{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary for correct and eacy insertion of tables\n",
    "hp_res = {}\n",
    "bt_res = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/si-hj/Desktop/medsegnet')\n",
    "sys.path.append('/home/si-hj/Desktop')\n",
    "import numpy as np\n",
    "from ast import mod\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import Dict, Tuple\n",
    "import torchio as tio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import data\n",
    "from data.datasets import MedicalDecathlonDataset, ModalitiesDataset\n",
    "\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import nibabel as nib\n",
    "from medsegnet.utils.metrics import dice_coefficient, dice_coefficient_classes, accuracy_score\n",
    "from medsegnet.utils.utils import setup_seed\n",
    "from hydra.utils import instantiate\n",
    "import os\n",
    "from data.datasets import MedicalDecathlonDataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#fcba03\">Data simulation</span>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generel code Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_params(model_dir):\n",
    "\tif not model_dir.is_dir():\n",
    "\t\traise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n",
    "\t\n",
    "\tmodel_path = f\"{model_dir}/best_model.pth\"\n",
    "\tcfg = OmegaConf.load(f\"{model_dir}/config.yaml\")\n",
    "\t\n",
    "\tsetup_seed(cfg.seed)\n",
    "\t\n",
    "\tif not isinstance(cfg, DictConfig):\n",
    "\t\traise TypeError(\"cfg must be a DictConfig.\")\n",
    "\n",
    "\treturn model_path, cfg\n",
    "\n",
    "def pp_list(lst):\n",
    "\treturn [f\"{dice:.3f}\" for dice in lst]\n",
    "\n",
    "def print_results(dsc_results_per_scale, datasets = None, lowest_dice_plt = False, latex = False):\n",
    "\tdice_scales = []\n",
    "\tclass_scales = []\n",
    "\tlatex_row = \"\"\n",
    "\tfor scale, results_list in dsc_results_per_scale.items():\n",
    "\t\tresults = np.mean(results_list, axis=1)\n",
    "\t\tmean_pr_class = np.mean(results_list, axis=0)\n",
    "\t\tclass_scales.append(mean_pr_class)\n",
    "\t\tstd_pr_class = np.std(results_list, axis=0)\n",
    "\n",
    "\t\tmean_pr_class = [f\"{dice:.3f}\" for dice in mean_pr_class]\n",
    "\t\tstd_pr_class = [f\"{std:.3f}\" for std in std_pr_class]\n",
    "\n",
    "\t\tlowest_idx = None\n",
    "\t\tlowest_dice = float('inf')\n",
    "\n",
    "\t\tif datasets is not None and lowest_dice_plt:\n",
    "\t\t\tfor i, dice in enumerate(results):\n",
    "\t\t\t\t\n",
    "\t\t\t\tif 0.87 < dice and dice < lowest_dice:\n",
    "\t\t\t\t\tlowest_dice = dice\n",
    "\t\t\t\t\tlowest_idx = i\n",
    "\n",
    "\t\tif datasets is not None:\n",
    "\t\t\tmax_idx, max_dice = datasets[scale] @ np.argmax(results), np.max(results)\n",
    "\t\t\tmin_idx, min_dice = datasets[scale] @ np.argmin(results), np.min(results)\n",
    "\n",
    "\t\t\n",
    "\t\tmean_dice = np.mean(results)\n",
    "\t\tdice_scales.append(mean_dice)\n",
    "\t\tstd_dice = np.std(results)\n",
    "\t\tlatex_row += f\"{mean_dice:.3f} \\pm {std_dice:.3f} & \"\n",
    "\t\tstr = f\"Scale {scale}) Mean Dice: {mean_dice:.3f}\\t Std: {std_dice:.3f}\\t Mean Pr. Class Dice: {mean_pr_class}\\t Std Pr. Class: {std_pr_class}\"\n",
    "\t\tif datasets:\n",
    "\t\t\tif lowest_idx is not None and lowest_dice_plt:\n",
    "\t\t\t\tprint(f\"\\tChosen image: {datasets[scale] @ lowest_idx} = {lowest_dice:.3f} DSC\")\n",
    "\t\t\tprint(str + f\"\\t\\tMax Dice({max_idx}): {max_dice:.3f}\\t Min Dice({min_idx}): {min_dice:.3f}\" if datasets is not None else str)\n",
    "\t\telse:\n",
    "\t\t\tprint(str)\n",
    "\tprint(f\"Mean Dice across all scales: {np.mean(dice_scales):.3f} \\t Std: {np.std(dice_scales):.3f}\")\n",
    "\tprint(f\"Mean Dice across all scales of classess: {pp_list(np.mean(class_scales, axis=0))} \\t Std: {pp_list(np.std(class_scales, axis=0))}\")\n",
    "\tif latex:\n",
    "\t\tlatex_row += f\"{np.mean(dice_scales):.3f} \\pm {np.std(dice_scales):.3f} \\\\\\\\\"\n",
    "\t\tprint(f\"Latex: {latex_row}\")\n",
    "\t\n",
    "\tprint()\n",
    "\n",
    "def consistent_dice(pred, label, num_classes):\n",
    "\treturn dice_coefficient_classes(\n",
    "\t\t\tpred, label, num_classes, ignore_index=0\n",
    "\t\t)\n",
    "\n",
    "def plot_img(image, pred, label):\n",
    "\timage = image[0, 1, :, :, :]\n",
    "\tpred = pred.cpu()\n",
    "\n",
    "\tmax_shape = max(image.shape)\n",
    "\tcp = CropOrPad((max_shape, max_shape, max_shape))\n",
    "\timage = cp(image.unsqueeze(0)).squeeze(0)\n",
    "\tlabel = cp(label[:, :, :].unsqueeze(0)).squeeze(0)\n",
    "\tpred = cp(pred[:, :, :].unsqueeze(0)).squeeze(0)\n",
    "\t\n",
    "\n",
    "\t# Extract slices\n",
    "\taxial_image = np.rot90(image[:, :, image.shape[2] // 2])\n",
    "\tcoronal_image = np.rot90(image[:, image.shape[1] // 2, :])\n",
    "\tsagittal_image = np.rot90(image[image.shape[0] // 2, :, :])\n",
    "\t\n",
    "\taxial_label = np.rot90(label[:, :, label.shape[2] // 2])\n",
    "\tcoronal_label = np.rot90(label[:, label.shape[1] // 2, :])\n",
    "\tsagittal_label = np.rot90(label[label.shape[0] // 2, :, :])\n",
    "\n",
    "\t\n",
    "\taxial_pred = np.rot90(pred[:, :, pred.shape[2] // 2])\n",
    "\tcoronal_pred = np.rot90(pred[:, pred.shape[1] // 2, :])\n",
    "\tsagittal_pred = np.rot90(pred[pred.shape[0] // 2, :, :])\n",
    "\n",
    "\timages = [\n",
    "\t\taxial_image, axial_label, axial_pred,\n",
    "\t\tcoronal_image, coronal_label, coronal_pred,\n",
    "\t\tsagittal_image, sagittal_label, sagittal_pred\n",
    "\t]\n",
    "\n",
    "\ttitles_x = [\"Image\", \"Label\", \"Prediction\"]\n",
    "\ttitles_y = [\"Axial\", \"Coronal\", \"Sagittal\"]\n",
    "\n",
    "\t\n",
    "\tfig, axs = plt.subplots(3, 3, figsize=(9, 9))\n",
    "\tfor i in range(3):\n",
    "\t\tfor j in range(3):\n",
    "\t\t\taxs[i, j].imshow(images[i * 3 + j], cmap=\"gray\")\n",
    "\t\t\t# axs[i, j].axis(\"off\")\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\taxs[i, j].set_title(titles_x[j])\n",
    "\t\t\t\t\n",
    "\t\t\tif j == 0:\n",
    "\t\t\t\tlabel_obj = axs[i, j].set_ylabel(titles_y[i], rotation=90, labelpad=20)\n",
    "\t\t\t\tlabel_obj.set_verticalalignment('center')\n",
    "\t\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_config = {\n",
    "    \"Task01_BrainTumour\": {\n",
    "        \"best_models_paths\": {\n",
    "            \"bb\": \"trained_models/unet3d/Task01_BrainTumour/2025-07-01_02:56:40_Brats-Baseline-UNet\",\n",
    "            \"aug\": \"trained_models/unet-aug3d/Task01_BrainTumour/2025-07-01_02:56:40_Brats-Baseline-UNet-Aug\", \n",
    "            \"ms\": \"trained_models/ms-unet3d/Task01_BrainTumour/2025-07-01_02:56:40_Brats-RAREUNet-Final\"    \n",
    "        },\n",
    "    },\n",
    "    \"Task04_Hippocampus\": {\n",
    "        \"best_models_paths\": {\n",
    "            \"bb\": \"trained_models/unet3d/Task04_Hippocampus/2025-07-01_02:56:37_Hippo-Baseline-UNet\",\n",
    "            \"aug\": \"trained_models/unet-aug3d/Task04_Hippocampus/2025-07-01_02:56:37_Hippo-Baseline-UNet-Aug\",\n",
    "            \"ms\": \"trained_models/ms-unet3d/Task04_Hippocampus/2025-07-01_02:56:37_Hippo-RAREUNet-Final\"\n",
    "        },\n",
    "    },\n",
    "    \"Task05_Prostate\": {\n",
    "        \"best_models_paths\": {\n",
    "            \"bb\": \"\",\n",
    "            \"aug\": \"\",\n",
    "            \"ms\": \"\" # \"trained_models/ms-unet3d/Task05_Prostate/2025-06-14_18:28:37_test_prostate_instance/\"\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSimulation -- Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: training = True\n",
      "INFO: depth = 4\n",
      "INFO: target_shape = [32, 64, 32]\n",
      "INFO: in_channels = 1\n",
      "INFO: n_filters = 15\n",
      "INFO: dropout = 0.1\n",
      "INFO: num_classes = 3\n",
      "INFO: norm_type = instance\n",
      "INFO: activation_type = leaky_relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** HippoCampus ********************\n",
      "MSUNet3D: MODE=inference\n",
      "******************* TEST LowRes HippoCampus | Best Model (Multiscale) *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:00<00:00, 56.24it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:00<00:00, 89.74it/s] \n",
      "Scale 2: 100%|██████████| 52/52 [00:00<00:00, 94.43it/s] \n",
      "Scale 3: 100%|██████████| 52/52 [00:00<00:00, 100.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.870\t Std: 0.034\t Mean Pr. Class Dice: ['0.878', '0.862']\t Std Pr. Class: ['0.035', '0.040']\t\tMax Dice(hippocampus_227.nii.gz): 0.928\t Min Dice(hippocampus_282.nii.gz): 0.775\n",
      "Scale 1) Mean Dice: 0.861\t Std: 0.040\t Mean Pr. Class Dice: ['0.869', '0.853']\t Std Pr. Class: ['0.042', '0.042']\t\tMax Dice(hippocampus_065.nii.gz): 0.923\t Min Dice(hippocampus_320.nii.gz): 0.735\n",
      "Scale 2) Mean Dice: 0.823\t Std: 0.062\t Mean Pr. Class Dice: ['0.839', '0.808']\t Std Pr. Class: ['0.075', '0.067']\t\tMax Dice(hippocampus_044.nii.gz): 0.928\t Min Dice(hippocampus_199.nii.gz): 0.652\n",
      "Scale 3) Mean Dice: 0.771\t Std: 0.101\t Mean Pr. Class Dice: ['0.797', '0.744']\t Std Pr. Class: ['0.142', '0.166']\t\tMax Dice(hippocampus_044.nii.gz): 1.000\t Min Dice(hippocampus_199.nii.gz): 0.500\n",
      "Mean Dice across all scales: 0.831 \t Std: 0.039\n",
      "Mean Dice across all scales of classess: ['0.846', '0.817'] \t Std: ['0.032', '0.047']\n",
      "Latex: 0.870 \\pm 0.034 & 0.861 \\pm 0.040 & 0.823 \\pm 0.062 & 0.771 \\pm 0.101 & 0.831 \\pm 0.039 \\\\\n",
      "\n",
      "******************** Prostate ********************\n",
      "******************** BrainTumour ********************\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "from networkx import center\n",
    "import test\n",
    "from torchio import CropOrPad\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def test_lowres(model_dir_str: str, desc: str = \"\", classes: bool = True, plot: bool = False, num_ms_levels: int = 3):\n",
    "\tif model_dir_str is None or model_dir_str == \"\":\n",
    "\t\tprint(\"No model directory provided.\")\n",
    "\t\treturn\n",
    "\tif not model_dir_str.startswith(\"/home/si-hj/Desktop/medsegnet/\"):\n",
    "\t\tmodel_dir_str = \"/home/si-hj/Desktop/medsegnet/\" + model_dir_str\n",
    "\tmodel_dir = Path(model_dir_str)\n",
    "\tmodel_path, cfg = model_params(model_dir)\n",
    "\n",
    "\tscales = list(range(num_ms_levels+1))\n",
    "\n",
    "\n",
    "\tbase_dir = Path(cfg.dataset.base_path)\n",
    "\tif not str(base_dir).endswith(\"_test1\"):\n",
    "\t\tbase_dir = Path(f\"{base_dir}_test1\")\n",
    "\t\t\n",
    "\tlowres_dir = base_dir / \"lowres\" / \"downsampled\"\n",
    "\n",
    "\tdatasets = {}\n",
    "\n",
    "\tfor scale in scales:\n",
    "\t\timg_dir = lowres_dir / f\"scale{scale}\" / \"imagesTs\"\n",
    "\t\tlbl_dir = lowres_dir / f\"scale{scale}\" / \"labelsTs\"\n",
    "\t\timg_dir_sort = sorted(os.listdir(img_dir))\n",
    "\t\tlbl_dir_sort = sorted(os.listdir(lbl_dir))\n",
    "\t\tif (cfg.dataset.name == \"Task04_Hippocampus\"):\n",
    "\t\t\tdataset = MedicalDecathlonDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\t\telse:\n",
    "\t\t\tdataset = ModalitiesDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\t\tdatasets[scale] = dataset\n",
    "\n",
    "\n",
    "\t\n",
    "\tmodel = instantiate(cfg.architecture.path, cfg, \"inference\")\n",
    "\n",
    "\tcheckpoint = torch.load(model_path, map_location=device)\n",
    "\tmodel_state_dict = checkpoint[\"model_state_dict\"]\n",
    "\tmodel.load_state_dict(model_state_dict)\n",
    "\tmodel.to(device)\n",
    "\tmodel.eval()\n",
    "\n",
    "\tdsc_results_per_scale = {scale: [] for scale in scales}\n",
    "\n",
    "\tprint(f\"******************* TEST LowRes {desc + ' ' if desc != '' else ''}*******************\")\n",
    "\tfor scale in scales:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tdataloader = DataLoader(datasets[scale], batch_size=1, shuffle=False, num_workers=cfg.training.num_workers)\n",
    "\t\t\tfor idx, (image, label) in tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Scale {scale}\"):\n",
    "\t\t\t\t\n",
    "\t\t\t\toutput = model.run_inference(image.to(device))\n",
    "\t\t\t\tpred = torch.argmax(output, dim=1).squeeze(0)\n",
    "\t\t\t\tlabel = label.squeeze(0)\n",
    "\t\t\t\t\n",
    "\t\t\t\tdsc_pr_class = consistent_dice(pred, label.to(device), cfg.dataset.num_classes)\n",
    "\t\t\t\tdsc_results_per_scale[scale].append([dsc_class.item() for dsc_class in dsc_pr_class])\n",
    "\n",
    "\t\t\t\tif plot and (scale == 0 and np.mean(dsc_pr_class) <= 0.3 or np.mean(dsc_pr_class) < 0.1):\n",
    "\t\t\t\t\tprint(f\"dice: {dsc_pr_class.item()}\\t{datasets[scale] @ idx}\")\n",
    "\t\t\t\t\tplot_img(image, pred, label)\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\tprint(f\"Results per scale of lowres:\")\n",
    "\tprint_results(dsc_results_per_scale, datasets, lowest_dice_plt=False, latex=True)\n",
    "\treturn dsc_results_per_scale\n",
    "\n",
    "for path, task in [\n",
    "\t# (\"trained_models/ms-unet3d/Task01_BrainTumour/2025-06-13_18:28:57_msinstance_0dropout_msgate-instancenorm\", \"bt - check\"),\n",
    " \t# (\"trained_models/ms-unet3d/Task01_BrainTumour/2025-06-13_03:34:22_msinstance_full\", \"bt - test\")\t\n",
    "]:\n",
    "\tif not path.startswith(\"/home/si-hj/Desktop/medsegnet/\") and path != \"\":\n",
    "\t\tpath = \"/home/si-hj/Desktop/medsegnet/\" + path\n",
    "\tif not os.path.exists(path):\n",
    "\t\tprint(f\"Path does not exist: {path}\")\n",
    "\t\tcontinue\n",
    "\ttest_lowres(path, f\"quciktest | Test runs {task} Models (Multiscale)\")\n",
    "\n",
    "# Hippocampus\n",
    "print(f\"{'*' * 20} HippoCampus {'*' * 20}\")\n",
    "hp_res[\"our\"] = test_lowres(_dataset_config['Task04_Hippocampus']['best_models_paths'].get('ms'), \"HippoCampus | Best Model (Multiscale)\")\n",
    "\n",
    "# Prostate\n",
    "print(f\"{'*' * 20} Prostate {'*' * 20}\")\n",
    "# test_lowres(_dataset_config['Task05_Prostate']['best_models_paths'].get('ms'), \"Prostate | Best Model (Multiscale)\")\n",
    "\n",
    "# BrainTumour\n",
    "print(f\"{'*' * 20} BrainTumour {'*' * 20}\")\n",
    "#bt_res[\"our\"] = test_lowres(_dataset_config['Task01_BrainTumour']['best_models_paths'].get('ms'), \"BrainTumour | Best Model (Multiscale)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSimulation -- BackBone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: training = True\n",
      "INFO: depth = 4\n",
      "INFO: target_shape = [32, 64, 32]\n",
      "INFO: in_channels = 1\n",
      "INFO: n_filters = 15\n",
      "INFO: dropout = 0.1\n",
      "INFO: num_classes = 3\n",
      "INFO: norm_type = instance\n",
      "INFO: activation_type = leaky_relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** HippoCampus ********************\n",
      "******************* TEST Pad/upsamp HippoCampus | Best U-Net3D *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:03<00:00, 14.96it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:03<00:00, 15.69it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:03<00:00, 15.89it/s]\n",
      "Scale 3:   0%|          | 0/52 [00:00<?, ?it/s]/home/si-hj/.conda/envs/bp/lib/python3.10/site-packages/torchio/transforms/preprocessing/intensity/rescale.py:89: RuntimeWarning: Rescaling image \"image\" not possible because all the intensity values are the same\n",
      "  image.set_data(self.rescale(image.data, mask, image_name))\n",
      "Scale 3: 100%|██████████| 52/52 [00:03<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of pad:\n",
      "Scale 0) Mean Dice: 0.879\t Std: 0.033\t Mean Pr. Class Dice: ['0.887', '0.870']\t Std Pr. Class: ['0.033', '0.039']\t\tMax Dice(hippocampus_373.nii.gz): 0.927\t Min Dice(hippocampus_282.nii.gz): 0.795\n",
      "Scale 1) Mean Dice: 0.196\t Std: 0.064\t Mean Pr. Class Dice: ['0.106', '0.286']\t Std Pr. Class: ['0.096', '0.055']\t\tMax Dice(hippocampus_223.nii.gz): 0.366\t Min Dice(hippocampus_274.nii.gz): 0.071\n",
      "Scale 2) Mean Dice: 0.115\t Std: 0.039\t Mean Pr. Class Dice: ['0.139', '0.092']\t Std Pr. Class: ['0.029', '0.071']\t\tMax Dice(hippocampus_227.nii.gz): 0.226\t Min Dice(hippocampus_003.nii.gz): 0.062\n",
      "Scale 3) Mean Dice: 0.048\t Std: 0.039\t Mean Pr. Class Dice: ['0.077', '0.019']\t Std Pr. Class: ['0.037', '0.066']\t\tMax Dice(hippocampus_321.nii.gz): 0.183\t Min Dice(hippocampus_172.nii.gz): 0.000\n",
      "Mean Dice across all scales: 0.310 \t Std: 0.333\n",
      "Mean Dice across all scales of classess: ['0.302', '0.317'] \t Std: ['0.338', '0.334']\n",
      "Latex: 0.879 \\pm 0.033 & 0.196 \\pm 0.064 & 0.115 \\pm 0.039 & 0.048 \\pm 0.039 & 0.310 \\pm 0.333 \\\\\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:02<00:00, 21.75it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:02<00:00, 22.87it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:02<00:00, 22.60it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:02<00:00, 21.50it/s]\n",
      "INFO: training = True\n",
      "INFO: depth = 4\n",
      "INFO: target_shape = [32, 64, 32]\n",
      "INFO: in_channels = 1\n",
      "INFO: n_filters = 15\n",
      "INFO: dropout = 0.1\n",
      "INFO: num_classes = 3\n",
      "INFO: norm_type = instance\n",
      "INFO: activation_type = leaky_relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of upsampled:\n",
      "Scale 0) Mean Dice: 0.879\t Std: 0.033\t Mean Pr. Class Dice: ['0.887', '0.870']\t Std Pr. Class: ['0.033', '0.039']\t\tMax Dice(hippocampus_373.nii.gz): 0.927\t Min Dice(hippocampus_282.nii.gz): 0.795\n",
      "Scale 1) Mean Dice: 0.843\t Std: 0.050\t Mean Pr. Class Dice: ['0.855', '0.832']\t Std Pr. Class: ['0.049', '0.066']\t\tMax Dice(hippocampus_065.nii.gz): 0.919\t Min Dice(hippocampus_173.nii.gz): 0.683\n",
      "Scale 2) Mean Dice: 0.741\t Std: 0.090\t Mean Pr. Class Dice: ['0.747', '0.735']\t Std Pr. Class: ['0.087', '0.120']\t\tMax Dice(hippocampus_065.nii.gz): 0.881\t Min Dice(hippocampus_199.nii.gz): 0.406\n",
      "Scale 3) Mean Dice: 0.293\t Std: 0.141\t Mean Pr. Class Dice: ['0.497', '0.088']\t Std Pr. Class: ['0.232', '0.177']\t\tMax Dice(hippocampus_320.nii.gz): 0.583\t Min Dice(hippocampus_274.nii.gz): 0.000\n",
      "Mean Dice across all scales: 0.689 \t Std: 0.234\n",
      "Mean Dice across all scales of classess: ['0.747', '0.631'] \t Std: ['0.153', '0.317']\n",
      "Latex: 0.879 \\pm 0.033 & 0.843 \\pm 0.050 & 0.741 \\pm 0.090 & 0.293 \\pm 0.141 & 0.689 \\pm 0.234 \\\\\n",
      "\n",
      "\n",
      "\n",
      "BackboneAugmented: MODE=inference\n",
      "******************* TEST Pad/upsamp HippoCampus | Best U-Net-aug3D *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:03<00:00, 15.45it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:03<00:00, 16.03it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:03<00:00, 15.61it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:03<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of pad:\n",
      "Scale 0) Mean Dice: 0.876\t Std: 0.033\t Mean Pr. Class Dice: ['0.883', '0.869']\t Std Pr. Class: ['0.033', '0.036']\t\tMax Dice(hippocampus_373.nii.gz): 0.925\t Min Dice(hippocampus_223.nii.gz): 0.807\n",
      "Scale 1) Mean Dice: 0.230\t Std: 0.042\t Mean Pr. Class Dice: ['0.270', '0.190']\t Std Pr. Class: ['0.054', '0.045']\t\tMax Dice(hippocampus_368.nii.gz): 0.326\t Min Dice(hippocampus_350.nii.gz): 0.146\n",
      "Scale 2) Mean Dice: 0.042\t Std: 0.032\t Mean Pr. Class Dice: ['0.060', '0.023']\t Std Pr. Class: ['0.049', '0.028']\t\tMax Dice(hippocampus_373.nii.gz): 0.109\t Min Dice(hippocampus_040.nii.gz): 0.000\n",
      "Scale 3) Mean Dice: 0.000\t Std: 0.003\t Mean Pr. Class Dice: ['0.000', '0.001']\t Std Pr. Class: ['0.000', '0.005']\t\tMax Dice(hippocampus_242.nii.gz): 0.019\t Min Dice(hippocampus_003.nii.gz): 0.000\n",
      "Mean Dice across all scales: 0.287 \t Std: 0.351\n",
      "Mean Dice across all scales of classess: ['0.303', '0.271'] \t Std: ['0.349', '0.353']\n",
      "Latex: 0.876 \\pm 0.033 & 0.230 \\pm 0.042 & 0.042 \\pm 0.032 & 0.000 \\pm 0.003 & 0.287 \\pm 0.351 \\\\\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:02<00:00, 21.52it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:02<00:00, 22.54it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:02<00:00, 21.90it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:02<00:00, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of upsampled:\n",
      "Scale 0) Mean Dice: 0.876\t Std: 0.033\t Mean Pr. Class Dice: ['0.883', '0.869']\t Std Pr. Class: ['0.033', '0.036']\t\tMax Dice(hippocampus_373.nii.gz): 0.925\t Min Dice(hippocampus_223.nii.gz): 0.807\n",
      "Scale 1) Mean Dice: 0.863\t Std: 0.040\t Mean Pr. Class Dice: ['0.871', '0.856']\t Std Pr. Class: ['0.039', '0.046']\t\tMax Dice(hippocampus_044.nii.gz): 0.933\t Min Dice(hippocampus_173.nii.gz): 0.766\n",
      "Scale 2) Mean Dice: 0.826\t Std: 0.065\t Mean Pr. Class Dice: ['0.839', '0.812']\t Std Pr. Class: ['0.078', '0.073']\t\tMax Dice(hippocampus_094.nii.gz): 0.950\t Min Dice(hippocampus_199.nii.gz): 0.650\n",
      "Scale 3) Mean Dice: 0.791\t Std: 0.130\t Mean Pr. Class Dice: ['0.783', '0.798']\t Std Pr. Class: ['0.148', '0.196']\t\tMax Dice(hippocampus_094.nii.gz): 1.000\t Min Dice(hippocampus_173.nii.gz): 0.365\n",
      "Mean Dice across all scales: 0.839 \t Std: 0.033\n",
      "Mean Dice across all scales of classess: ['0.844', '0.834'] \t Std: ['0.039', '0.029']\n",
      "Latex: 0.876 \\pm 0.033 & 0.863 \\pm 0.040 & 0.826 \\pm 0.065 & 0.791 \\pm 0.130 & 0.839 \\pm 0.033 \\\\\n",
      "\n",
      "\n",
      "\n",
      "******************** Prostate ********************\n",
      "******************** BrainTumour ********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_backbone(model_dir_str, desc: str = \"\", depth: int = 3):\n",
    "\tif model_dir_str is None or model_dir_str == \"\":\n",
    "\t\tprint(\"No model directory provided.\")\n",
    "\t\treturn\n",
    "\tif not model_dir_str.startswith(\"/home/si-hj/Desktop/medsegnet/\"):\n",
    "\t\tmodel_dir_str = \"/home/si-hj/Desktop/medsegnet/\" + model_dir_str\n",
    "\tmodel_dir = Path(model_dir_str)\n",
    "\tmodel_path, cfg = model_params(model_dir)\n",
    "\t\n",
    "\tscales = list(range(depth+1))\n",
    "\n",
    "\n",
    "\tbase_dir = Path(cfg.dataset.base_path)\n",
    "\tif not str(base_dir).endswith(\"_test1\"):\n",
    "\t\tbase_dir = Path(f\"{base_dir}_test1\")\n",
    "\n",
    "\tpad_dir = base_dir / \"fullres\" / \"pad\"\n",
    "\tupsampling_dir = base_dir / \"fullres\" / \"upsampled\"\n",
    "\tdatasets = {}\n",
    "\n",
    "\tdef get_dataset(base_name_dir, name):\n",
    "\t\tdatasets[name] = {}\n",
    "\t\tfor scale in scales:\n",
    "\t\t\timg_dir = os.path.join(base_name_dir, f\"scale{scale}\", \"imagesTs\")\n",
    "\t\t\tlbl_dir = os.path.join(base_dir, \"lowres\", \"downsampled\", f\"scale{scale}\", \"labelsTs\")\n",
    "\t\t\timg_dir_sort = sorted(os.listdir(img_dir))\n",
    "\t\t\tlbl_dir_sort = sorted(os.listdir(lbl_dir))\n",
    "\t\t\tif (cfg.dataset.name == \"Task01_BrainTumour\"):\n",
    "\t\t\t\tdataset = ModalitiesDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\t\t\telse:\n",
    "\t\t\t\tdataset = MedicalDecathlonDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\t\t\tdatasets[name][scale] = dataset\n",
    "\n",
    "\tget_dataset(pad_dir, \"pad\")\n",
    "\tget_dataset(upsampling_dir, \"upsampled\")\n",
    "\n",
    "\tmodel = instantiate(cfg.architecture.path, cfg, mode=\"inference\")\n",
    "\n",
    "\tcheckpoint = torch.load(model_path, map_location=device)\n",
    "\tmodel_state_dict = checkpoint[\"model_state_dict\"]\n",
    "\tmodel.load_state_dict(model_state_dict)\n",
    "\tmodel.to(device)\n",
    "\tmodel.eval()\n",
    "\n",
    "\t# dsc_results_per_scale = {scale: [] for scale in scales} moved this inside so its not averaged over pad and upsampled....\n",
    "\tprint(f\"******************* TEST Pad/upsamp {desc + ' ' if desc != '' else ''}*******************\")\n",
    "\tdef test(dataset, name):\n",
    "\t\tdsc_results_per_scale = {scale: [] for scale in scales} \n",
    "\t\tfor scale in scales:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tfor idx, (image, label) in tqdm(enumerate(dataset[name][scale]), desc=f\"Scale {scale}\", total=len(dataset[name][scale])):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tx = image.unsqueeze(0).float().to(device)\n",
    "\n",
    "\t\t\t\t\toutput = model.forward(x)\n",
    "\n",
    "\t\t\t\t\toutput = output.argmax(dim=1).unsqueeze(0) \n",
    "\n",
    "\t\t\t\t\ttarget_shape = tuple(label.shape)\n",
    "\n",
    "\t\t\t\t\tif name == \"pad\": # crop to target shape\n",
    "\t\t\t\t\t\tcp = tio.CropOrPad(target_shape, padding_mode=\"constant\")\n",
    "\t\t\t\t\t\ttio_image = tio.ScalarImage(tensor=output.squeeze(0))\n",
    "\n",
    "\t\t\t\t\t\tscaled_output = cp(tio_image)\n",
    "\t\t\t\t\t\tscaled_output = (scaled_output.data).unsqueeze(0)\n",
    "\t\t\t\t\telse: # downsample to target shape\n",
    "\t\t\t\t\t\tscaled_output = F.interpolate(\n",
    "\t\t\t\t\t\t\toutput.float(), size=target_shape, mode=\"nearest\"\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\tlabel = label.unsqueeze(0)\n",
    "\n",
    "\t\t\t\t\tpred = scaled_output.squeeze(0)\n",
    "\t\t\t\t\t# pred = torch.argmax(scaled_output, dim=1)\n",
    "\n",
    "\t\t\t\t\tdsc_pr_class = consistent_dice(pred.to(device), label.to(device), cfg.dataset.num_classes)\n",
    "\t\t\t\t\tdsc_results_per_scale[scale].append([dsc_class.item() for dsc_class in dsc_pr_class])\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\tprint(f\"Results per scale of {name}:\")\n",
    "\t\tprint_results(dsc_results_per_scale, dataset[name], latex=True)\n",
    "\t\treturn dsc_results_per_scale\n",
    "\t\t\n",
    "\tpad_res = test(datasets, \"pad\")\n",
    "\tup_res = test(datasets, \"upsampled\")\n",
    "\tprint(\"\\n\")\n",
    "\treturn pad_res, up_res\n",
    "\n",
    "\n",
    "# Hippocampus\n",
    "print(f\"{'*' * 20} HippoCampus {'*' * 20}\")\n",
    "hp_res[\"bb_pad\"], hp_res[\"bb_up\"] = test_backbone(_dataset_config['Task04_Hippocampus']['best_models_paths'].get('bb'), \"HippoCampus | Best U-Net3D\")\n",
    "hp_res[\"bb-aug_pad\"], hp_res[\"bb-aug_up\"] = test_backbone(_dataset_config['Task04_Hippocampus']['best_models_paths'].get('aug'), \"HippoCampus | Best U-Net-aug3D\")\n",
    "\n",
    "# Prostate\n",
    "print(f\"{'*' * 20} Prostate {'*' * 20}\")\n",
    "# test_backbone(_dataset_config['Task05_Prostate']['best_models_paths'].get('bb'), \"Prostate | Best U-Net3D\")\n",
    "# test_backbone(_dataset_config['Task05_Prostate']['best_models_paths'].get('aug'), \"Prostate | Best U-Net-aug3D\")\n",
    "\n",
    "# Braintumour\n",
    "print(f\"{'*' * 20} BrainTumour {'*' * 20}\")\n",
    "#bt_res[\"bb_pad\"], bt_res[\"bb_up\"] = test_backbone(_dataset_config['Task01_BrainTumour']['best_models_paths'].get('bb'), \"BrainTumour | Best U-Net3D\")\n",
    "#bt_res[\"bb-aug_pad\"], bt_res[\"bb-aug_up\"] = test_backbone(_dataset_config['Task01_BrainTumour']['best_models_paths'].get('aug'), \"BrainTumour | Best U-Net-aug3D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSimulation -- NNUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** HippocCampus ********************\n",
      "TEST LowRes HP - Pad Best achieved for nnU-net:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:01<00:00, 39.14it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:01<00:00, 35.02it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:01<00:00, 35.24it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:01<00:00, 35.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.880\t Std: 0.032\t Mean Pr. Class Dice: ['0.889', '0.871']\t Std Pr. Class: ['0.033', '0.034']\n",
      "Scale 1) Mean Dice: 0.819\t Std: 0.045\t Mean Pr. Class Dice: ['0.835', '0.804']\t Std Pr. Class: ['0.038', '0.063']\n",
      "Scale 2) Mean Dice: 0.529\t Std: 0.097\t Mean Pr. Class Dice: ['0.552', '0.505']\t Std Pr. Class: ['0.111', '0.113']\n",
      "Scale 3) Mean Dice: 0.030\t Std: 0.062\t Mean Pr. Class Dice: ['0.054', '0.005']\t Std Pr. Class: ['0.120', '0.039']\n",
      "Mean Dice across all scales: 0.564 \t Std: 0.336\n",
      "Mean Dice across all scales of classess: ['0.582', '0.546'] \t Std: ['0.331', '0.341']\n",
      "Latex: 0.880 \\pm 0.032 & 0.819 \\pm 0.045 & 0.529 \\pm 0.097 & 0.030 \\pm 0.062 & 0.564 \\pm 0.336 \\\\\n",
      "\n",
      "TEST LowRes HP - Upsampled Best achieved for nnU-net:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:00<00:00, 199.81it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:00<00:00, 325.59it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:00<00:00, 337.88it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:00<00:00, 340.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.880\t Std: 0.032\t Mean Pr. Class Dice: ['0.889', '0.871']\t Std Pr. Class: ['0.033', '0.034']\n",
      "Scale 1) Mean Dice: 0.820\t Std: 0.067\t Mean Pr. Class Dice: ['0.831', '0.808']\t Std Pr. Class: ['0.066', '0.075']\n",
      "Scale 2) Mean Dice: 0.597\t Std: 0.106\t Mean Pr. Class Dice: ['0.586', '0.609']\t Std Pr. Class: ['0.135', '0.121']\n",
      "Scale 3) Mean Dice: 0.055\t Std: 0.085\t Mean Pr. Class Dice: ['0.087', '0.023']\t Std Pr. Class: ['0.135', '0.081']\n",
      "Mean Dice across all scales: 0.588 \t Std: 0.325\n",
      "Mean Dice across all scales of classess: ['0.598', '0.578'] \t Std: ['0.316', '0.334']\n",
      "Latex: 0.880 \\pm 0.032 & 0.820 \\pm 0.067 & 0.597 \\pm 0.106 & 0.055 \\pm 0.085 & 0.588 \\pm 0.325 \\\\\n",
      "\n",
      "******************** BrainTumour ********************\n",
      "TEST LowRes BT - Pad | Best achieved for nnU-net:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 97/97 [00:14<00:00,  6.91it/s]\n",
      "Scale 1: 100%|██████████| 97/97 [00:09<00:00, 10.28it/s]\n",
      "Scale 2: 100%|██████████| 97/97 [00:08<00:00, 10.92it/s]\n",
      "Scale 3: 100%|██████████| 97/97 [00:08<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.712\t Std: 0.152\t Mean Pr. Class Dice: ['0.794', '0.591', '0.752']\t Std Pr. Class: ['0.112', '0.253', '0.243']\n",
      "Scale 1) Mean Dice: 0.670\t Std: 0.152\t Mean Pr. Class Dice: ['0.765', '0.537', '0.706']\t Std Pr. Class: ['0.120', '0.256', '0.248']\n",
      "Scale 2) Mean Dice: 0.583\t Std: 0.128\t Mean Pr. Class Dice: ['0.682', '0.468', '0.598']\t Std Pr. Class: ['0.133', '0.234', '0.230']\n",
      "Scale 3) Mean Dice: 0.399\t Std: 0.125\t Mean Pr. Class Dice: ['0.491', '0.330', '0.377']\t Std Pr. Class: ['0.169', '0.211', '0.237']\n",
      "Mean Dice across all scales: 0.591 \t Std: 0.120\n",
      "Mean Dice across all scales of classess: ['0.683', '0.482', '0.608'] \t Std: ['0.119', '0.098', '0.145']\n",
      "Latex: 0.712 \\pm 0.152 & 0.670 \\pm 0.152 & 0.583 \\pm 0.128 & 0.399 \\pm 0.125 & 0.591 \\pm 0.120 \\\\\n",
      "\n",
      "TEST LowRes BT - Upsampled | Best achieved for nnU-net:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 97/97 [00:13<00:00,  7.27it/s]\n",
      "Scale 1: 100%|██████████| 97/97 [00:05<00:00, 18.56it/s]\n",
      "Scale 2: 100%|██████████| 97/97 [00:04<00:00, 21.27it/s]\n",
      "Scale 3: 100%|██████████| 97/97 [00:04<00:00, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.712\t Std: 0.152\t Mean Pr. Class Dice: ['0.794', '0.591', '0.752']\t Std Pr. Class: ['0.112', '0.253', '0.243']\n",
      "Scale 1) Mean Dice: 0.660\t Std: 0.155\t Mean Pr. Class Dice: ['0.750', '0.518', '0.711']\t Std Pr. Class: ['0.127', '0.255', '0.250']\n",
      "Scale 2) Mean Dice: 0.595\t Std: 0.140\t Mean Pr. Class Dice: ['0.698', '0.444', '0.644']\t Std Pr. Class: ['0.137', '0.244', '0.253']\n",
      "Scale 3) Mean Dice: 0.452\t Std: 0.145\t Mean Pr. Class Dice: ['0.553', '0.321', '0.482']\t Std Pr. Class: ['0.185', '0.233', '0.288']\n",
      "Mean Dice across all scales: 0.605 \t Std: 0.097\n",
      "Mean Dice across all scales of classess: ['0.699', '0.469', '0.647'] \t Std: ['0.091', '0.100', '0.103']\n",
      "Latex: 0.712 \\pm 0.152 & 0.660 \\pm 0.155 & 0.595 \\pm 0.140 & 0.452 \\pm 0.145 & 0.605 \\pm 0.097 \\\\\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pp\n",
    "from sympy import factor\n",
    "import yaml\n",
    "\n",
    "\n",
    "def test_nnUNet(pred_dir_str, desc: str = \"\", depth: int = 3):\n",
    "\tscales = list(range(depth+1))\n",
    "\n",
    "\tdataset_short_name, dataset_type = pred_dir_str.split(\"/\")\n",
    "\n",
    "\tdsc_results_per_scale = {scale: [] for scale in scales}\n",
    "\tprint(f\"TEST LowRes{' ' + desc if desc != '' else ''}:\")\n",
    "\tdataset = {\n",
    "\t\t\"hp\": \"Task04_Hippocampus\",\n",
    "\t\t\"bt\": \"Task01_BrainTumour\",\n",
    "\t\t\"p\": \"Task05_Prostate\",\n",
    "\t}\n",
    "\tdataset_name = dataset[dataset_short_name]\n",
    "\n",
    "\tfor scale in scales:\n",
    "\t\tlabel_name_str = f\"/home/si-hj/Desktop/datasets/{dataset_name}_test1/lowres/downsampled/scale{scale}/labelsTs\" \n",
    "\t\tlabel_name_dir = Path(label_name_str)\n",
    "\n",
    "\t\tpred_name_str = f\"/home/si-hj/Desktop/nn-unet/predictions/{pred_dir_str}/scale{scale}\"\n",
    "\t\tpred_name_dir = Path(pred_name_str)\n",
    "\t\t\n",
    "\t\timage_files = sorted([f for f in os.listdir(pred_name_dir) if f.endswith(\".nii.gz\")])\n",
    "\t\tlabel_files = sorted([f for f in os.listdir(label_name_dir) if f.endswith(\".nii.gz\")])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tfor img_file, label_file in tqdm(zip(image_files, label_files), desc=f\"Scale {scale}\", total=len(image_files)):\n",
    "\t\t\timg_path = pred_name_dir / img_file\n",
    "\t\t\tlabel_path = label_name_dir / label_file\n",
    "\t\t\t\n",
    "\n",
    "\t\t\timage = nib.load(str(img_path)).get_fdata() # (W, H, D)\n",
    "\t\t\tscaled_label = nib.load(str(label_path)).get_fdata() # (W, H, D)\n",
    "\n",
    "\t\t\tfactor = 1 / (2 ** scale)\n",
    "\t\t\tif dataset_type == \"pad\":\n",
    "\t\t\t\t# target shape\n",
    "\t\t\t\ttarget_shape = tuple(round(dim * factor) for dim in image.shape)\n",
    "\n",
    "\t\t\t\ttio_image = tio.ScalarImage(str(img_path)) # (C, W, H, D)\n",
    "\t\t\t\tcp = tio.CropOrPad(target_shape)\n",
    "\t\t\t\ttio_image = cp(tio_image)\n",
    "\t\t\t\tscaled_image = torch.from_numpy(tio_image.data.numpy()).squeeze(0) # (C, W, H, D) -> (C, D, H, W)\n",
    "\n",
    "\t\t\telif dataset_type == \"upsampled\":\n",
    "\t\t\t\ttensor = torch.from_numpy(image).unsqueeze(0).unsqueeze(0) # (W, H, D) -> (1, 1, D, H, W)\n",
    "\t\t\t\ttensor_out = F.interpolate(tensor, scale_factor=factor, mode=\"nearest\")\n",
    "\t\t\t\n",
    "\t\t\t\tscaled_image = tensor_out.squeeze(0).squeeze(0)\n",
    "\t\t\telse: \n",
    "\t\t\t\traise ValueError(f\"Unknown dataset type: {dataset_type} (available: pad, upsampled)\")\n",
    "\t\t\t\n",
    "\t\t\tscaled_label = torch.from_numpy(scaled_label)\n",
    "\n",
    "\t\t\t# get medsegnet/config/dataset/Task01_BrainTumour.yaml -> num_classes\n",
    "\t\t\tnum_classes = yaml.safe_load(open(f\"/home/si-hj/Desktop/medsegnet/config/dataset/{dataset_name}.yaml\"))['num_classes']\n",
    "\t\t\t\n",
    "\t\t\tdsc_pr_class = consistent_dice(\n",
    "\t\t\t\tscaled_image.to(device), scaled_label.to(device), num_classes\n",
    "\t\t\t)\n",
    "\t\t\tdsc_results_per_scale[scale].append([dsc_class.item() for dsc_class in dsc_pr_class])\n",
    "\t\t\t\n",
    "\tprint(f\"Results per scale of lowres:\")\n",
    "\tprint_results(dsc_results_per_scale, latex=True)\n",
    "\treturn dsc_results_per_scale\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "# Hippocampus\n",
    "print(f\"{'*' * 20} HippocCampus {'*' * 20}\")\n",
    "hp_res[\"nn_pad\"] = test_nnUNet(f\"hp/pad\", f\"HP - Pad Best achieved for nnU-net\")\n",
    "hp_res[\"nn_up\"] = test_nnUNet(f\"hp/upsampled\", f\"HP - Upsampled Best achieved for nnU-net\")\n",
    "\n",
    "# Prostate\n",
    "# print(f\"{'*' * 20} Prostate {'*' * 20}\")\n",
    "# test_nnUNet(f\"p/pad\", f\"P - Pad | Best achieved for nnU-net\")\n",
    "# test_nnUNet(f\"p/upsampled\", f\"P - Upsampled | Best achieved for nnU-net\")\n",
    "\n",
    "\n",
    "# Braintumour\n",
    "print(f\"{'*' * 20} BrainTumour {'*' * 20}\")\n",
    "bt_res[\"nn_pad\"] = test_nnUNet(f\"bt/pad\", f\"BT - Pad | Best achieved for nnU-net\")\n",
    "bt_res[\"nn_up\"] = test_nnUNet(f\"bt/upsampled\", f\"BT - Upsampled | Best achieved for nnU-net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary to print tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is for overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================== LaTeX Table Rows for Hippocampus ====================\n",
      "UNet--Pad & \\underline{0.879}$\\pm$0.033 & 0.196$\\pm$0.064 & 0.115$\\pm$0.039 & 0.048$\\pm$0.039 & 0.310$\\pm$0.333 \\\\\n",
      "UNet--Up & \\underline{0.879}$\\pm$0.033 & 0.843$\\pm$0.050 & 0.741$\\pm$0.090 & 0.293$\\pm$0.141 & 0.689$\\pm$0.234 \\\\\\midrule\n",
      "UNet+Aug--Pad & 0.876$\\pm$0.033 & 0.230$\\pm$0.042 & 0.042$\\pm$0.032 & 0.000$\\pm$0.003 & 0.287$\\pm$0.351 \\\\\n",
      "UNet+Aug--Up & 0.876$\\pm$0.033 & \\textbf{0.863}$\\pm$0.040 & \\textbf{0.826}$\\pm$0.065 & \\textbf{0.791}$\\pm$0.130 & \\textbf{0.839}$\\pm$0.033 \\\\\\midrule\n",
      "nnUNet--Pad & \\textbf{0.880}$\\pm$0.032 & 0.819$\\pm$0.045 & 0.529$\\pm$0.097 & 0.030$\\pm$0.062 & 0.564$\\pm$0.336 \\\\\n",
      "nnUNet--Up & \\textbf{0.880}$\\pm$0.032 & 0.820$\\pm$0.067 & 0.597$\\pm$0.106 & 0.055$\\pm$0.085 & 0.588$\\pm$0.325 \\\\\\midrule\n",
      "RARE-UNet & 0.870$\\pm$0.034 & \\underline{0.861}$\\pm$0.040 & \\underline{0.823}$\\pm$0.062 & \\underline{0.771}$\\pm$0.101 & \\underline{0.831}$\\pm$0.039 \\\\\n",
      "==================== End of Table ====================\n",
      "\n",
      "\n",
      "\n",
      "==================== LaTeX Table Rows for BrainTumour ====================\n",
      "nnUNet--Pad & \\textbf{0.712}$\\pm$0.152 & \\textbf{0.670}$\\pm$0.152 & \\underline{0.583}$\\pm$0.128 & \\underline{0.399}$\\pm$0.125 & \\underline{0.591}$\\pm$0.120 \\\\\n",
      "nnUNet--Up & \\textbf{0.712}$\\pm$0.152 & \\underline{0.660}$\\pm$0.155 & \\textbf{0.595}$\\pm$0.140 & \\textbf{0.452}$\\pm$0.145 & \\textbf{0.605}$\\pm$0.097 \\\\\n",
      "==================== End of Table ====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_latex_table(results_dict, model_names_map, table_title, scales_order=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Generates and prints LaTeX table rows from a dictionary of results.\n",
    "    It highlights the best (bold) and second-best (underline) values in each column\n",
    "    by comparing values rounded to 3 decimal places, correctly handling all ties.\n",
    "\n",
    "    Args:\n",
    "        results_dict (dict): The dictionary containing the model results (e.g., hp_res, bt_res).\n",
    "        model_names_map (dict): A map from keys in results_dict to display names for the table.\n",
    "        table_title (str): The title to print above the table.\n",
    "        scales_order (list): The order of scales to process.\n",
    "    \"\"\"\n",
    "    print(f\"\\n\\n{'='*20} LaTeX Table Rows for {table_title} {'='*20}\")\n",
    "    \n",
    "    # --- PASS 1: Pre-compute all data ---\n",
    "    all_models_data = []\n",
    "    model_keys_in_order = [key for key in model_names_map.keys() if key in results_dict and results_dict[key] is not None]\n",
    "\n",
    "    for model_key in model_keys_in_order:\n",
    "        dsc_results_per_scale = results_dict[model_key]\n",
    "        if not all(s in dsc_results_per_scale for s in scales_order):\n",
    "            continue\n",
    "        \n",
    "        model_means = []\n",
    "        model_stds = []\n",
    "        for scale in scales_order:\n",
    "            results_list = dsc_results_per_scale[scale]\n",
    "            results_mean_per_image = np.mean(results_list, axis=1)\n",
    "            model_means.append(np.mean(results_mean_per_image))\n",
    "            model_stds.append(np.std(results_mean_per_image))\n",
    "\n",
    "        overall_mean = np.mean(model_means)\n",
    "        overall_std = np.std(model_means)\n",
    "        model_means.append(overall_mean)\n",
    "        model_stds.append(overall_std)\n",
    "        \n",
    "        all_models_data.append({\n",
    "            'key': model_key,\n",
    "            'name': model_names_map[model_key],\n",
    "            'means': model_means,\n",
    "            'stds': model_stds\n",
    "        })\n",
    "\n",
    "    if not all_models_data:\n",
    "        print(f\"No valid data found for table: {table_title}\")\n",
    "        return\n",
    "\n",
    "    # --- PASS 2: Analyze columns using rounded values and generate table ---\n",
    "    means_array = np.array([data['means'] for data in all_models_data])\n",
    "    num_cols = means_array.shape[1]\n",
    "    \n",
    "    max_vals_per_col = []\n",
    "    second_max_vals_per_col = []\n",
    "\n",
    "    for j in range(num_cols):\n",
    "        # --- ROBUST LOGIC USING ROUNDING ---\n",
    "        # 1. Round all values in the column to 3 decimal places for comparison\n",
    "        col_values_rounded = np.round(means_array[:, j], 3)\n",
    "        \n",
    "        # 2. Get the unique sorted values from the rounded data\n",
    "        unique_sorted_desc = np.unique(col_values_rounded)[::-1]\n",
    "        \n",
    "        # 3. Assign the top two unique rounded values\n",
    "        max_val = unique_sorted_desc[0] if len(unique_sorted_desc) > 0 else -1.0\n",
    "        second_max_val = unique_sorted_desc[1] if len(unique_sorted_desc) > 1 else -1.0\n",
    "        \n",
    "        max_vals_per_col.append(max_val)\n",
    "        second_max_vals_per_col.append(second_max_val)\n",
    "\n",
    "    # --- Print Data Rows ---\n",
    "    for i, model_data in enumerate(all_models_data):\n",
    "        latex_parts = []\n",
    "        for j in range(num_cols):\n",
    "            mean = model_data['means'][j]\n",
    "            std = model_data['stds'][j]\n",
    "            \n",
    "            # Use the original mean for display formatting, but the rounded mean for logic\n",
    "            mean_for_comparison = round(mean, 3)\n",
    "            mean_str_for_display = f\"{mean:.3f}\"\n",
    "            \n",
    "            max_val = max_vals_per_col[j]\n",
    "            second_max_val = second_max_vals_per_col[j]\n",
    "\n",
    "            # Compare the rounded value against the stored rounded max/second_max\n",
    "            if mean_for_comparison == max_val:\n",
    "                formatted_mean = f\"\\\\textbf{{{mean_str_for_display}}}\"\n",
    "            elif mean_for_comparison == second_max_val:\n",
    "                formatted_mean = f\"\\\\underline{{{mean_str_for_display}}}\"\n",
    "            else:\n",
    "                formatted_mean = mean_str_for_display\n",
    "            \n",
    "            latex_parts.append(f\"{formatted_mean}$\\\\pm${std:.3f}\")\n",
    "        \n",
    "        row_content = \" & \".join(latex_parts)\n",
    "        \n",
    "        model_key = model_data['key']\n",
    "        \n",
    "        if model_key.endswith('_up') and i < len(all_models_data) - 1:\n",
    "             print(f\"{model_data['name']} & {row_content} \\\\\\\\\\\\midrule\")\n",
    "        else:\n",
    "             print(f\"{model_data['name']} & {row_content} \\\\\\\\\")\n",
    "\n",
    "    print(f\"{'='*20} End of Table {'='*20}\\n\")\n",
    "\n",
    "\n",
    "# The rest of your script remains the same\n",
    "model_names = {\n",
    "    \"bb_pad\": \"UNet--Pad\",\n",
    "    \"bb_up\": \"UNet--Up\",\n",
    "    \"bb-aug_pad\": \"UNet+Aug--Pad\",\n",
    "    \"bb-aug_up\": \"UNet+Aug--Up\",\n",
    "    \"nn_pad\": \"nnUNet--Pad\",\n",
    "    \"nn_up\": \"nnUNet--Up\",\n",
    "    \"our\": \"RARE-UNet\",\n",
    "}\n",
    "\n",
    "# The rest of your script, including where you call this function, remains the same.\n",
    "generate_latex_table(hp_res, model_names, \"Hippocampus\")\n",
    "generate_latex_table(bt_res, model_names, \"BrainTumour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is for all the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bb_pad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 111\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m End of Table \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# --- How to use ---\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# At the end of your script, after `hp_res` and `bt_res` are populated, call:\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m \u001b[43mgenerate_class_table_grouped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbt_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 57\u001b[0m, in \u001b[0;36mgenerate_class_table_grouped\u001b[0;34m(hp_res, bt_res)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, res_dict, class_idx \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 57\u001b[0m         class_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mres_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_key\u001b[49m\u001b[43m]\u001b[49m[scale])[:, class_idx]\n\u001b[1;32m     58\u001b[0m         mean, std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(class_scores), np\u001b[38;5;241m.\u001b[39mstd(class_scores)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# Handle 'Overall' calculation for this specific row\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bb_pad'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_class_table_grouped(hp_res, bt_res):\n",
    "    \"\"\"\n",
    "    Generates a LaTeX table for per-class Dice scores, applying formatting\n",
    "    (bold for best, underline for second-best) INDEPENDENTLY within each scale group.\n",
    "    Labels are formatted as 'Model--Pad' and 'Model--Up'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Configuration: Define the structure of the table ---\n",
    "    columns = [\n",
    "        ('HP--L', hp_res, 0), ('HP--R', hp_res, 1),\n",
    "        ('BT--PE', bt_res, 0), ('BT--NC', bt_res, 1), ('BT--ET', bt_res, 2),\n",
    "    ]\n",
    "    model_definitions = [\n",
    "        (\"UNet\", \"bb_pad\", \"bb_up\"),\n",
    "        (\"UNet+Aug\", \"bb-aug_pad\", \"bb-aug_up\"),\n",
    "        (\"nnUNet\", \"nn_pad\", \"nn_up\"),\n",
    "    ]\n",
    "    rare_unet_def = (\"RARE-UNet\", \"our\")\n",
    "    scales_config = [\n",
    "        (0, \"1\"), (1, \"1/2\"), (2, \"1/4\"), (3, \"1/8\"), ('overall', \"Overall\")\n",
    "    ]\n",
    "\n",
    "    # --- PASS 1: Collect all data, tagging each row with its scale group ---\n",
    "    all_rows_data = []\n",
    "\n",
    "    for scale, scale_name in scales_config:\n",
    "        current_group_data = []\n",
    "\n",
    "        # --- Define the rows for the current scale group ---\n",
    "        # For scale (1), only show the base models\n",
    "        if scale == 0:\n",
    "            for model_name, pad_key, _ in model_definitions:\n",
    "                current_group_data.append({'label': f\"{model_name} ({scale_name})\", 'model_key': pad_key})\n",
    "        # For other scales (not 'Overall'), show both Pad and Up variants\n",
    "        elif scale != 'overall':\n",
    "            for model_name, pad_key, up_key in model_definitions:\n",
    "                current_group_data.append({'label': f\"{model_name}--Pad ({scale_name})\", 'model_key': pad_key})\n",
    "                current_group_data.append({'label': f\"{model_name}--Up ({scale_name})\", 'model_key': up_key})\n",
    "        # For the 'Overall' group, also show both Pad and Up variants\n",
    "        elif scale == 'overall':\n",
    "            for model_name, pad_key, up_key in model_definitions:\n",
    "                current_group_data.append({'label': f\"{model_name}--Pad ({scale_name})\", 'model_key': pad_key})\n",
    "                current_group_data.append({'label': f\"{model_name}--Up ({scale_name})\", 'model_key': up_key})\n",
    "\n",
    "        # Add RARE-UNet to every group\n",
    "        current_group_data.append({'label': f\"{rare_unet_def[0]} ({scale_name})\", 'model_key': rare_unet_def[1]})\n",
    "        \n",
    "        # --- Calculate and store the data for each defined row ---\n",
    "        for row_info in current_group_data:\n",
    "            row_data = {'label': row_info['label'], 'scale_group': scale_name, 'means': [], 'stds': []}\n",
    "            model_key = row_info['model_key']\n",
    "            \n",
    "            for _, res_dict, class_idx in columns:\n",
    "                if scale != 'overall':\n",
    "                    class_scores = np.array(res_dict[model_key][scale])[:, class_idx]\n",
    "                    mean, std = np.mean(class_scores), np.std(class_scores)\n",
    "                else: # Handle 'Overall' calculation for this specific row\n",
    "                    means_per_scale = []\n",
    "                    for s in range(4): # Average across all 4 scales [0, 1, 2, 3]\n",
    "                        means_per_scale.append(np.mean(np.array(res_dict[model_key][s])[:, class_idx]))\n",
    "                    mean, std = np.mean(means_per_scale), np.std(means_per_scale)\n",
    "                \n",
    "                row_data['means'].append(mean)\n",
    "                row_data['stds'].append(std)\n",
    "            all_rows_data.append(row_data)\n",
    "\n",
    "    # --- PASS 2: Analyze and print, group by group ---\n",
    "    print(\"\\n\\n\" + \"=\"*20 + \" LaTeX Table for Per-Class DSC (Grouped) \" + \"=\"*20)\n",
    "    \n",
    "    for idx, (scale, scale_name) in enumerate(scales_config):\n",
    "        group_rows = [row for row in all_rows_data if row['scale_group'] == scale_name]\n",
    "        if not group_rows: continue\n",
    "\n",
    "        group_means_array = np.array([data['means'] for data in group_rows])\n",
    "        max_vals_for_group, second_max_vals_for_group = [], []\n",
    "        \n",
    "        for j in range(group_means_array.shape[1]):\n",
    "            col_values_rounded = np.round(group_means_array[:, j], 3)\n",
    "            unique_sorted_desc = np.unique(col_values_rounded)[::-1]\n",
    "            max_vals_for_group.append(unique_sorted_desc[0] if len(unique_sorted_desc) > 0 else -1.0)\n",
    "            second_max_vals_for_group.append(unique_sorted_desc[1] if len(unique_sorted_desc) > 1 else -1.0)\n",
    "\n",
    "        for row_data in group_rows:\n",
    "            latex_parts = []\n",
    "            for j in range(len(columns)):\n",
    "                mean, std = row_data['means'][j], row_data['stds'][j]\n",
    "                mean_for_comparison = round(mean, 3)\n",
    "                mean_str_for_display = f\"{mean:.3f}\"\n",
    "                \n",
    "                if mean_for_comparison == max_vals_for_group[j]:\n",
    "                    formatted_mean = f\"\\\\textbf{{{mean_str_for_display}}}\"\n",
    "                elif mean_for_comparison == second_max_vals_for_group[j]:\n",
    "                    formatted_mean = f\"\\\\underline{{{mean_str_for_display}}}\"\n",
    "                else:\n",
    "                    formatted_mean = mean_str_for_display\n",
    "                \n",
    "                latex_parts.append(f\"{formatted_mean}$\\\\pm${std:.3f}\")\n",
    "            \n",
    "            print(f\"{row_data['label']} & \" + \" & \".join(latex_parts) + \" \\\\\\\\\")\n",
    "\n",
    "        if idx < len(scales_config) - 1:\n",
    "            print(\"\\\\midrule\")\n",
    "            \n",
    "    print(\"=\"*20 + \" End of Table \" + \"=\"*20 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- How to use ---\n",
    "# At the end of your script, after `hp_res` and `bt_res` are populated, call:\n",
    "generate_class_table_grouped(hp_res, bt_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
