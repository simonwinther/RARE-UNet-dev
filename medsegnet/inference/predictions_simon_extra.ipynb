{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary for correct and eacy insertion of tables\n",
    "hp_res = {}\n",
    "bt_res = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/si-hj/Desktop/medsegnet')\n",
    "sys.path.append('/home/si-hj/Desktop')\n",
    "import numpy as np\n",
    "from ast import mod\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import Dict, Tuple\n",
    "import torchio as tio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import data\n",
    "from data.datasets import MedicalDecathlonDataset, ModalitiesDataset\n",
    "from utils.assertions import ensure\n",
    "\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import nibabel as nib\n",
    "from utils.metrics import dice_coefficient, dice_coefficient_classes, accuracy_score\n",
    "from utils.utils import setup_seed\n",
    "from hydra.utils import instantiate\n",
    "import os\n",
    "from data.datasets import MedicalDecathlonDataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#fcba03\">Data simulation</span>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generel code Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_params(model_dir):\n",
    "\tif not model_dir.is_dir():\n",
    "\t\traise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n",
    "\t\n",
    "\tmodel_path = f\"{model_dir}/best_model.pth\"\n",
    "\tcfg = OmegaConf.load(f\"{model_dir}/config.yaml\")\n",
    "\t\n",
    "\tsetup_seed(cfg.seed)\n",
    "\t\n",
    "\tif not isinstance(cfg, DictConfig):\n",
    "\t\traise TypeError(\"cfg must be a DictConfig.\")\n",
    "\n",
    "\treturn model_path, cfg\n",
    "\n",
    "def pp_list(lst):\n",
    "\treturn [f\"{dice:.4f}\" for dice in lst]\n",
    "\n",
    "def print_results(dsc_results_per_scale, datasets = None, lowest_dice_plt = False, latex = False):\n",
    "\tdice_scales = []\n",
    "\tclass_scales = []\n",
    "\tlatex_row = \"\"\n",
    "\tfor scale, results_list in dsc_results_per_scale.items():\n",
    "\t\tresults = np.mean(results_list, axis=1)\n",
    "\t\tmean_pr_class = np.mean(results_list, axis=0)\n",
    "\t\tclass_scales.append(mean_pr_class)\n",
    "\t\tstd_pr_class = np.std(results_list, axis=0)\n",
    "\n",
    "\t\tmean_pr_class = [f\"{dice:.4f}\" for dice in mean_pr_class]\n",
    "\t\tstd_pr_class = [f\"{std:.4f}\" for std in std_pr_class]\n",
    "\n",
    "\t\tlowest_idx = None\n",
    "\t\tlowest_dice = float('inf')\n",
    "\n",
    "\t\tif datasets is not None and lowest_dice_plt:\n",
    "\t\t\tfor i, dice in enumerate(results):\n",
    "\t\t\t\t\n",
    "\t\t\t\tif 0.87 < dice and dice < lowest_dice:\n",
    "\t\t\t\t\tlowest_dice = dice\n",
    "\t\t\t\t\tlowest_idx = i\n",
    "\n",
    "\t\tif datasets is not None:\n",
    "\t\t\tmax_idx, max_dice = datasets[scale] @ np.argmax(results), np.max(results)\n",
    "\t\t\tmin_idx, min_dice = datasets[scale] @ np.argmin(results), np.min(results)\n",
    "\n",
    "\t\t\n",
    "\t\tmean_dice = np.mean(results)\n",
    "\t\tdice_scales.append(mean_dice)\n",
    "\t\tstd_dice = np.std(results)\n",
    "\t\tlatex_row += f\"{mean_dice:.4f} \\pm {std_dice:.4f} & \"\n",
    "\t\tstr = f\"Scale {scale}) Mean Dice: {mean_dice:.4f}\\t Std: {std_dice:.4f}\\t Mean Pr. Class Dice: {mean_pr_class}\\t Std Pr. Class: {std_pr_class}\"\n",
    "\t\tif datasets:\n",
    "\t\t\tif lowest_idx is not None and lowest_dice_plt:\n",
    "\t\t\t\tprint(f\"\\tChosen image: {datasets[scale] @ lowest_idx} = {lowest_dice:.4f} DSC\")\n",
    "\t\t\tprint(str + f\"\\t\\tMax Dice({max_idx}): {max_dice:.4f}\\t Min Dice({min_idx}): {min_dice:.4f}\" if datasets is not None else str)\n",
    "\t\telse:\n",
    "\t\t\tprint(str)\n",
    "\tprint(f\"Mean Dice across all scales: {np.mean(dice_scales):.4f} \\t Std: {np.std(dice_scales):.4f}\")\n",
    "\tprint(f\"Mean Dice across all scales of classess: {pp_list(np.mean(class_scales, axis=0))} \\t Std: {pp_list(np.std(class_scales, axis=0))}\")\n",
    "\tif latex:\n",
    "\t\tlatex_row += f\"{np.mean(dice_scales):.4f} \\pm {np.std(dice_scales):.4f} \\\\\\\\\"\n",
    "\t\tprint(f\"Latex: {latex_row}\")\n",
    "\t\n",
    "\tprint()\n",
    "\n",
    "def consistent_dice(pred, label, num_classes):\n",
    "\treturn dice_coefficient_classes(\n",
    "\t\t\tpred, label, num_classes, ignore_index=0\n",
    "\t\t)\n",
    "\n",
    "def plot_img(image, pred, label):\n",
    "\timage = image[0, 1, :, :, :]\n",
    "\tpred = pred.cpu()\n",
    "\n",
    "\tmax_shape = max(image.shape)\n",
    "\tcp = CropOrPad((max_shape, max_shape, max_shape))\n",
    "\timage = cp(image.unsqueeze(0)).squeeze(0)\n",
    "\tlabel = cp(label[:, :, :].unsqueeze(0)).squeeze(0)\n",
    "\tpred = cp(pred[:, :, :].unsqueeze(0)).squeeze(0)\n",
    "\t\n",
    "\n",
    "\t# Extract slices\n",
    "\taxial_image = np.rot90(image[:, :, image.shape[2] // 2])\n",
    "\tcoronal_image = np.rot90(image[:, image.shape[1] // 2, :])\n",
    "\tsagittal_image = np.rot90(image[image.shape[0] // 2, :, :])\n",
    "\t\n",
    "\taxial_label = np.rot90(label[:, :, label.shape[2] // 2])\n",
    "\tcoronal_label = np.rot90(label[:, label.shape[1] // 2, :])\n",
    "\tsagittal_label = np.rot90(label[label.shape[0] // 2, :, :])\n",
    "\n",
    "\t\n",
    "\taxial_pred = np.rot90(pred[:, :, pred.shape[2] // 2])\n",
    "\tcoronal_pred = np.rot90(pred[:, pred.shape[1] // 2, :])\n",
    "\tsagittal_pred = np.rot90(pred[pred.shape[0] // 2, :, :])\n",
    "\n",
    "\timages = [\n",
    "\t\taxial_image, axial_label, axial_pred,\n",
    "\t\tcoronal_image, coronal_label, coronal_pred,\n",
    "\t\tsagittal_image, sagittal_label, sagittal_pred\n",
    "\t]\n",
    "\n",
    "\ttitles_x = [\"Image\", \"Label\", \"Prediction\"]\n",
    "\ttitles_y = [\"Axial\", \"Coronal\", \"Sagittal\"]\n",
    "\n",
    "\t\n",
    "\tfig, axs = plt.subplots(3, 3, figsize=(9, 9))\n",
    "\tfor i in range(3):\n",
    "\t\tfor j in range(3):\n",
    "\t\t\taxs[i, j].imshow(images[i * 3 + j], cmap=\"gray\")\n",
    "\t\t\t# axs[i, j].axis(\"off\")\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\taxs[i, j].set_title(titles_x[j])\n",
    "\t\t\t\t\n",
    "\t\t\tif j == 0:\n",
    "\t\t\t\tlabel_obj = axs[i, j].set_ylabel(titles_y[i], rotation=90, labelpad=20)\n",
    "\t\t\t\tlabel_obj.set_verticalalignment('center')\n",
    "\t\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset_config = {\n",
    "    \"Task01_BrainTumour\": {\n",
    "        \"best_models_paths\": {\n",
    "            \"bb\": \"trained_models/unet3d/Task01_BrainTumour/2025-07-01_02:56:40_Brats-Baseline-UNet\",\n",
    "            \"aug\": \"trained_models/unet-aug3d/Task01_BrainTumour/2025-07-01_02:56:40_Brats-Baseline-UNet-Aug\", \n",
    "            \"ms\": \"trained_models/ms-unet3d/Task01_BrainTumour/2025-07-01_02:56:40_Brats-RAREUNet-Final\"    \n",
    "        },\n",
    "    },\n",
    "    \"Task04_Hippocampus\": {\n",
    "        \"best_models_paths\": {\n",
    "            \"bb\": \"trained_models/unet3d/Task04_Hippocampus/2025-07-01_02:56:37_Hippo-Baseline-UNet\",\n",
    "            \"aug\": \"trained_models/unet-aug3d/Task04_Hippocampus/2025-07-01_02:56:37_Hippo-Baseline-UNet-Aug\",\n",
    "            \"ms\": \"trained_models/ms-unet3d/Task04_Hippocampus/2025-07-01_02:56:37_Hippo-RAREUNet-Final\"\n",
    "        },\n",
    "    },\n",
    "    \"Task05_Prostate\": {\n",
    "        \"best_models_paths\": {\n",
    "            \"bb\": \"\",\n",
    "            \"aug\": \"\",\n",
    "            \"ms\": \"\" # \"trained_models/ms-unet3d/Task05_Prostate/2025-06-14_18:28:37_test_prostate_instance/\"\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSimulation -- Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** HippoCampus ********************\n",
      "MSUNet3D: MODE=inference\n",
      "******************* TEST LowRes HippoCampus | Best Model (Multiscale) *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:00<00:00, 53.09it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:00<00:00, 78.60it/s] \n",
      "Scale 2: 100%|██████████| 52/52 [00:00<00:00, 88.50it/s] \n",
      "Scale 3: 100%|██████████| 52/52 [00:00<00:00, 72.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.8692\t Std: 0.0318\t Mean Pr. Class Dice: ['0.8781', '0.8603']\t Std Pr. Class: ['0.0318', '0.0375']\t\tMax Dice(hippocampus_227.nii.gz): 0.9190\t Min Dice(hippocampus_282.nii.gz): 0.7972\n",
      "Scale 1) Mean Dice: 0.8624\t Std: 0.0373\t Mean Pr. Class Dice: ['0.8685', '0.8562']\t Std Pr. Class: ['0.0406', '0.0419']\t\tMax Dice(hippocampus_088.nii.gz): 0.9220\t Min Dice(hippocampus_320.nii.gz): 0.7437\n",
      "Scale 2) Mean Dice: 0.8348\t Std: 0.0634\t Mean Pr. Class Dice: ['0.8459', '0.8237']\t Std Pr. Class: ['0.0771', '0.0642']\t\tMax Dice(hippocampus_094.nii.gz): 0.9412\t Min Dice(hippocampus_320.nii.gz): 0.6151\n",
      "Scale 3) Mean Dice: 0.7848\t Std: 0.1342\t Mean Pr. Class Dice: ['0.7787', '0.7910']\t Std Pr. Class: ['0.1954', '0.1770']\t\tMax Dice(hippocampus_023.nii.gz): 1.0000\t Min Dice(hippocampus_015.nii.gz): 0.3750\n",
      "Mean Dice across all scales: 0.8378 \t Std: 0.0332\n",
      "Mean Dice across all scales of classess: ['0.8428', '0.8328'] \t Std: ['0.0388', '0.0280']\n",
      "Latex: 0.8692 \\pm 0.0318 & 0.8624 \\pm 0.0373 & 0.8348 \\pm 0.0634 & 0.7848 \\pm 0.1342 & 0.8378 \\pm 0.0332 \\\\\n",
      "\n",
      "******************** Prostate ********************\n",
      "******************** BrainTumour ********************\n",
      "MSUNet3D: MODE=inference\n",
      "******************* TEST LowRes BrainTumour | Best Model (Multiscale) *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 97/97 [00:51<00:00,  1.89it/s]\n",
      "Scale 1: 100%|██████████| 97/97 [00:06<00:00, 15.88it/s]\n",
      "Scale 2: 100%|██████████| 97/97 [00:01<00:00, 53.79it/s]\n",
      "Scale 3: 100%|██████████| 97/97 [00:01<00:00, 93.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.6932\t Std: 0.1593\t Mean Pr. Class Dice: ['0.7776', '0.5855', '0.7166']\t Std Pr. Class: ['0.1282', '0.2302', '0.2632']\t\tMax Dice(BRATS_396.nii.gz): 0.9408\t Min Dice(BRATS_024.nii.gz): 0.2176\n",
      "Scale 1) Mean Dice: 0.6934\t Std: 0.1542\t Mean Pr. Class Dice: ['0.7875', '0.5870', '0.7057']\t Std Pr. Class: ['0.1201', '0.2312', '0.2657']\t\tMax Dice(BRATS_396.nii.gz): 0.9275\t Min Dice(BRATS_380.nii.gz): 0.2538\n",
      "Scale 2) Mean Dice: 0.6517\t Std: 0.1384\t Mean Pr. Class Dice: ['0.7599', '0.5241', '0.6711']\t Std Pr. Class: ['0.1201', '0.2468', '0.2484']\t\tMax Dice(BRATS_396.nii.gz): 0.8852\t Min Dice(BRATS_380.nii.gz): 0.2185\n",
      "Scale 3) Mean Dice: 0.5669\t Std: 0.1616\t Mean Pr. Class Dice: ['0.6682', '0.4627', '0.5699']\t Std Pr. Class: ['0.1464', '0.2634', '0.2828']\t\tMax Dice(BRATS_175.nii.gz): 0.8947\t Min Dice(BRATS_380.nii.gz): 0.1689\n",
      "Mean Dice across all scales: 0.6513 \t Std: 0.0516\n",
      "Mean Dice across all scales of classess: ['0.7483', '0.5398', '0.6658'] \t Std: ['0.0473', '0.0512', '0.0579']\n",
      "Latex: 0.6932 \\pm 0.1593 & 0.6934 \\pm 0.1542 & 0.6517 \\pm 0.1384 & 0.5669 \\pm 0.1616 & 0.6513 \\pm 0.0516 \\\\\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "from networkx import center\n",
    "import test\n",
    "from torchio import CropOrPad\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def test_lowres(model_dir_str: str, desc: str = \"\", classes: bool = True, plot: bool = False, num_ms_levels: int = 3):\n",
    "\tif model_dir_str is None or model_dir_str == \"\":\n",
    "\t\tprint(\"No model directory provided.\")\n",
    "\t\treturn\n",
    "\tif not model_dir_str.startswith(\"/home/si-hj/Desktop/medsegnet/\"):\n",
    "\t\tmodel_dir_str = \"/home/si-hj/Desktop/medsegnet/\" + model_dir_str\n",
    "\tmodel_dir = Path(model_dir_str)\n",
    "\tmodel_path, cfg = model_params(model_dir)\n",
    "\n",
    "\tscales = list(range(num_ms_levels+1))\n",
    "\n",
    "\n",
    "\tbase_dir = Path(cfg.dataset.base_path)\n",
    "\tif not str(base_dir).endswith(\"_test1\"):\n",
    "\t\tbase_dir = Path(f\"{base_dir}_test1\")\n",
    "\t\t\n",
    "\tlowres_dir = base_dir / \"lowres\" / \"downsampled\"\n",
    "\n",
    "\tdatasets = {}\n",
    "\n",
    "\tfor scale in scales:\n",
    "\t\timg_dir = lowres_dir / f\"scale{scale}\" / \"imagesTs\"\n",
    "\t\tlbl_dir = lowres_dir / f\"scale{scale}\" / \"labelsTs\"\n",
    "\t\timg_dir_sort = sorted(os.listdir(img_dir))\n",
    "\t\tlbl_dir_sort = sorted(os.listdir(lbl_dir))\n",
    "\t\tif (cfg.dataset.name == \"Task04_Hippocampus\"):\n",
    "\t\t\tdataset = MedicalDecathlonDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\t\telse:\n",
    "\t\t\tdataset = ModalitiesDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\t\tdatasets[scale] = dataset\n",
    "\n",
    "\n",
    "\t\n",
    "\tmodel = instantiate(cfg.architecture.path, cfg, \"inference\")\n",
    "\n",
    "\tcheckpoint = torch.load(model_path, map_location=device)\n",
    "\tmodel_state_dict = checkpoint[\"model_state_dict\"]\n",
    "\tmodel.load_state_dict(model_state_dict)\n",
    "\tmodel.to(device)\n",
    "\tmodel.eval()\n",
    "\n",
    "\tdsc_results_per_scale = {scale: [] for scale in scales}\n",
    "\n",
    "\tprint(f\"******************* TEST LowRes {desc + ' ' if desc != '' else ''}*******************\")\n",
    "\tfor scale in scales:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tdataloader = DataLoader(datasets[scale], batch_size=1, shuffle=False, num_workers=cfg.training.num_workers)\n",
    "\t\t\tfor idx, (image, label) in tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Scale {scale}\"):\n",
    "\t\t\t\t\n",
    "\t\t\t\toutput = model.run_inference(image.to(device))\n",
    "\t\t\t\tpred = torch.argmax(output, dim=1).squeeze(0)\n",
    "\t\t\t\tlabel = label.squeeze(0)\n",
    "\t\t\t\t\n",
    "\t\t\t\tdsc_pr_class = consistent_dice(pred, label.to(device), cfg.dataset.num_classes)\n",
    "\t\t\t\tdsc_results_per_scale[scale].append([dsc_class.item() for dsc_class in dsc_pr_class])\n",
    "\n",
    "\t\t\t\tif plot and (scale == 0 and np.mean(dsc_pr_class) <= 0.3 or np.mean(dsc_pr_class) < 0.1):\n",
    "\t\t\t\t\tprint(f\"dice: {dsc_pr_class.item()}\\t{datasets[scale] @ idx}\")\n",
    "\t\t\t\t\tplot_img(image, pred, label)\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\tprint(f\"Results per scale of lowres:\")\n",
    "\tprint_results(dsc_results_per_scale, datasets, lowest_dice_plt=False, latex=True)\n",
    "\treturn dsc_results_per_scale\n",
    "\n",
    "for path, task in [\n",
    "\t# (\"trained_models/ms-unet3d/Task01_BrainTumour/2025-06-13_18:28:57_msinstance_0dropout_msgate-instancenorm\", \"bt - check\"),\n",
    " \t# (\"trained_models/ms-unet3d/Task01_BrainTumour/2025-06-13_03:34:22_msinstance_full\", \"bt - test\")\t\n",
    "]:\n",
    "\tif not path.startswith(\"/home/si-hj/Desktop/medsegnet/\") and path != \"\":\n",
    "\t\tpath = \"/home/si-hj/Desktop/medsegnet/\" + path\n",
    "\tif not os.path.exists(path):\n",
    "\t\tprint(f\"Path does not exist: {path}\")\n",
    "\t\tcontinue\n",
    "\ttest_lowres(path, f\"quciktest | Test runs {task} Models (Multiscale)\")\n",
    "\n",
    "# Hippocampus\n",
    "print(f\"{'*' * 20} HippoCampus {'*' * 20}\")\n",
    "hp_res[\"our\"] = test_lowres(_dataset_config['Task04_Hippocampus']['best_models_paths'].get('ms'), \"HippoCampus | Best Model (Multiscale)\")\n",
    "\n",
    "# Prostate\n",
    "print(f\"{'*' * 20} Prostate {'*' * 20}\")\n",
    "# test_lowres(_dataset_config['Task05_Prostate']['best_models_paths'].get('ms'), \"Prostate | Best Model (Multiscale)\")\n",
    "\n",
    "# BrainTumour\n",
    "print(f\"{'*' * 20} BrainTumour {'*' * 20}\")\n",
    "bt_res[\"our\"] = test_lowres(_dataset_config['Task01_BrainTumour']['best_models_paths'].get('ms'), \"BrainTumour | Best Model (Multiscale)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSimulation -- BackBone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** HippoCampus ********************\n",
      "******************* TEST Pad/upsamp HippoCampus | Best U-Net3D *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:03<00:00, 15.45it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:03<00:00, 15.95it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:03<00:00, 15.95it/s]\n",
      "Scale 3:   0%|          | 0/52 [00:00<?, ?it/s]/home/si-hj/.conda/envs/bp/lib/python3.10/site-packages/torchio/transforms/preprocessing/intensity/rescale.py:89: RuntimeWarning: Rescaling image \"image\" not possible because all the intensity values are the same\n",
      "  image.set_data(self.rescale(image.data, mask, image_name))\n",
      "Scale 3: 100%|██████████| 52/52 [00:03<00:00, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of pad:\n",
      "Scale 0) Mean Dice: 0.8741\t Std: 0.0369\t Mean Pr. Class Dice: ['0.8864', '0.8617']\t Std Pr. Class: ['0.0308', '0.0500']\t\tMax Dice(hippocampus_227.nii.gz): 0.9347\t Min Dice(hippocampus_173.nii.gz): 0.7675\n",
      "Scale 1) Mean Dice: 0.0343\t Std: 0.0332\t Mean Pr. Class Dice: ['0.0126', '0.0559']\t Std Pr. Class: ['0.0358', '0.0577']\t\tMax Dice(hippocampus_376.nii.gz): 0.1270\t Min Dice(hippocampus_015.nii.gz): 0.0000\n",
      "Scale 2) Mean Dice: 0.0000\t Std: 0.0000\t Mean Pr. Class Dice: ['0.0000', '0.0000']\t Std Pr. Class: ['0.0000', '0.0000']\t\tMax Dice(hippocampus_003.nii.gz): 0.0000\t Min Dice(hippocampus_003.nii.gz): 0.0000\n",
      "Scale 3) Mean Dice: 0.0000\t Std: 0.0000\t Mean Pr. Class Dice: ['0.0000', '0.0000']\t Std Pr. Class: ['0.0000', '0.0000']\t\tMax Dice(hippocampus_003.nii.gz): 0.0000\t Min Dice(hippocampus_003.nii.gz): 0.0000\n",
      "Mean Dice across all scales: 0.2271 \t Std: 0.3738\n",
      "Mean Dice across all scales of classess: ['0.2247', '0.2294'] \t Std: ['0.3820', '0.3658']\n",
      "Latex: 0.8741 \\pm 0.0369 & 0.0343 \\pm 0.0332 & 0.0000 \\pm 0.0000 & 0.0000 \\pm 0.0000 & 0.2271 \\pm 0.3738 \\\\\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:02<00:00, 21.70it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:02<00:00, 22.34it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:02<00:00, 23.85it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:02<00:00, 24.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of upsampled:\n",
      "Scale 0) Mean Dice: 0.8741\t Std: 0.0369\t Mean Pr. Class Dice: ['0.8864', '0.8617']\t Std Pr. Class: ['0.0308', '0.0500']\t\tMax Dice(hippocampus_227.nii.gz): 0.9347\t Min Dice(hippocampus_173.nii.gz): 0.7675\n",
      "Scale 1) Mean Dice: 0.8476\t Std: 0.0577\t Mean Pr. Class Dice: ['0.8638', '0.8314']\t Std Pr. Class: ['0.0460', '0.0788']\t\tMax Dice(hippocampus_242.nii.gz): 0.9195\t Min Dice(hippocampus_199.nii.gz): 0.6436\n",
      "Scale 2) Mean Dice: 0.7764\t Std: 0.0830\t Mean Pr. Class Dice: ['0.7877', '0.7652']\t Std Pr. Class: ['0.0711', '0.1184']\t\tMax Dice(hippocampus_242.nii.gz): 0.9028\t Min Dice(hippocampus_173.nii.gz): 0.4872\n",
      "Scale 3) Mean Dice: 0.3339\t Std: 0.1502\t Mean Pr. Class Dice: ['0.5355', '0.1322']\t Std Pr. Class: ['0.2326', '0.1981']\t\tMax Dice(hippocampus_286.nii.gz): 0.7500\t Min Dice(hippocampus_011.nii.gz): 0.0000\n",
      "Mean Dice across all scales: 0.7080 \t Std: 0.2189\n",
      "Mean Dice across all scales of classess: ['0.7684', '0.6477'] \t Std: ['0.1393', '0.2996']\n",
      "Latex: 0.8741 \\pm 0.0369 & 0.8476 \\pm 0.0577 & 0.7764 \\pm 0.0830 & 0.3339 \\pm 0.1502 & 0.7080 \\pm 0.2189 \\\\\n",
      "\n",
      "\n",
      "\n",
      "BackboneAugmented: MODE=inference\n",
      "******************* TEST Pad/upsamp HippoCampus | Best U-Net-aug3D *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:03<00:00, 16.46it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:03<00:00, 16.41it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:03<00:00, 16.26it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:03<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of pad:\n",
      "Scale 0) Mean Dice: 0.8705\t Std: 0.0338\t Mean Pr. Class Dice: ['0.8786', '0.8625']\t Std Pr. Class: ['0.0333', '0.0377']\t\tMax Dice(hippocampus_227.nii.gz): 0.9251\t Min Dice(hippocampus_298.nii.gz): 0.8045\n",
      "Scale 1) Mean Dice: 0.2132\t Std: 0.0343\t Mean Pr. Class Dice: ['0.2584', '0.1680']\t Std Pr. Class: ['0.0504', '0.0396']\t\tMax Dice(hippocampus_286.nii.gz): 0.2745\t Min Dice(hippocampus_199.nii.gz): 0.1250\n",
      "Scale 2) Mean Dice: 0.0660\t Std: 0.0258\t Mean Pr. Class Dice: ['0.1036', '0.0283']\t Std Pr. Class: ['0.0443', '0.0228']\t\tMax Dice(hippocampus_368.nii.gz): 0.1405\t Min Dice(hippocampus_320.nii.gz): 0.0240\n",
      "Scale 3) Mean Dice: 0.0000\t Std: 0.0000\t Mean Pr. Class Dice: ['0.0000', '0.0000']\t Std Pr. Class: ['0.0000', '0.0000']\t\tMax Dice(hippocampus_003.nii.gz): 0.0000\t Min Dice(hippocampus_003.nii.gz): 0.0000\n",
      "Mean Dice across all scales: 0.2874 \t Std: 0.3454\n",
      "Mean Dice across all scales of classess: ['0.3102', '0.2647'] \t Std: ['0.3408', '0.3509']\n",
      "Latex: 0.8705 \\pm 0.0338 & 0.2132 \\pm 0.0343 & 0.0660 \\pm 0.0258 & 0.0000 \\pm 0.0000 & 0.2874 \\pm 0.3454 \\\\\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:02<00:00, 21.94it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:02<00:00, 22.06it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:02<00:00, 22.83it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:02<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of upsampled:\n",
      "Scale 0) Mean Dice: 0.8705\t Std: 0.0338\t Mean Pr. Class Dice: ['0.8786', '0.8625']\t Std Pr. Class: ['0.0333', '0.0377']\t\tMax Dice(hippocampus_227.nii.gz): 0.9251\t Min Dice(hippocampus_298.nii.gz): 0.8045\n",
      "Scale 1) Mean Dice: 0.8601\t Std: 0.0394\t Mean Pr. Class Dice: ['0.8665', '0.8537']\t Std Pr. Class: ['0.0396', '0.0447']\t\tMax Dice(hippocampus_044.nii.gz): 0.9206\t Min Dice(hippocampus_320.nii.gz): 0.7622\n",
      "Scale 2) Mean Dice: 0.8220\t Std: 0.0693\t Mean Pr. Class Dice: ['0.8313', '0.8128']\t Std Pr. Class: ['0.0871', '0.0731']\t\tMax Dice(hippocampus_094.nii.gz): 0.9572\t Min Dice(hippocampus_199.nii.gz): 0.6050\n",
      "Scale 3) Mean Dice: 0.7891\t Std: 0.1305\t Mean Pr. Class Dice: ['0.7933', '0.7849']\t Std Pr. Class: ['0.1531', '0.1929']\t\tMax Dice(hippocampus_023.nii.gz): 1.0000\t Min Dice(hippocampus_173.nii.gz): 0.3651\n",
      "Mean Dice across all scales: 0.8354 \t Std: 0.0323\n",
      "Mean Dice across all scales of classess: ['0.8424', '0.8285'] \t Std: ['0.0332', '0.0314']\n",
      "Latex: 0.8705 \\pm 0.0338 & 0.8601 \\pm 0.0394 & 0.8220 \\pm 0.0693 & 0.7891 \\pm 0.1305 & 0.8354 \\pm 0.0323 \\\\\n",
      "\n",
      "\n",
      "\n",
      "******************** Prostate ********************\n",
      "******************** BrainTumour ********************\n",
      "******************* TEST Pad/upsamp BrainTumour | Best U-Net3D *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 97/97 [02:48<00:00,  1.74s/it]\n",
      "Scale 1: 100%|██████████| 97/97 [02:24<00:00,  1.49s/it]\n",
      "Scale 2: 100%|██████████| 97/97 [02:16<00:00,  1.41s/it]\n",
      "Scale 3: 100%|██████████| 97/97 [02:17<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of pad:\n",
      "Scale 0) Mean Dice: 0.6992\t Std: 0.1540\t Mean Pr. Class Dice: ['0.7885', '0.5808', '0.7285']\t Std Pr. Class: ['0.1206', '0.2356', '0.2559']\t\tMax Dice(BRATS_396.nii.gz): 0.9391\t Min Dice(BRATS_024.nii.gz): 0.2581\n",
      "Scale 1) Mean Dice: 0.2083\t Std: 0.1244\t Mean Pr. Class Dice: ['0.3317', '0.2526', '0.0405']\t Std Pr. Class: ['0.2256', '0.2464', '0.0497']\t\tMax Dice(BRATS_217.nii.gz): 0.4957\t Min Dice(BRATS_175.nii.gz): 0.0088\n",
      "Scale 2) Mean Dice: 0.1760\t Std: 0.1144\t Mean Pr. Class Dice: ['0.2760', '0.2202', '0.0317']\t Std Pr. Class: ['0.1941', '0.2393', '0.0317']\t\tMax Dice(BRATS_275.nii.gz): 0.4414\t Min Dice(BRATS_380.nii.gz): 0.0016\n",
      "Scale 3) Mean Dice: 0.0662\t Std: 0.0618\t Mean Pr. Class Dice: ['0.0985', '0.0755', '0.0245']\t Std Pr. Class: ['0.1188', '0.1384', '0.0257']\t\tMax Dice(BRATS_143.nii.gz): 0.2208\t Min Dice(BRATS_175.nii.gz): 0.0000\n",
      "Mean Dice across all scales: 0.2874 \t Std: 0.2435\n",
      "Mean Dice across all scales of classess: ['0.3737', '0.2823', '0.2063'] \t Std: ['0.2545', '0.1848', '0.3015']\n",
      "Latex: 0.6992 \\pm 0.1540 & 0.2083 \\pm 0.1244 & 0.1760 \\pm 0.1144 & 0.0662 \\pm 0.0618 & 0.2874 \\pm 0.2435 \\\\\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 97/97 [02:47<00:00,  1.73s/it]\n",
      "Scale 1: 100%|██████████| 97/97 [02:37<00:00,  1.62s/it]\n",
      "Scale 2: 100%|██████████| 97/97 [02:36<00:00,  1.62s/it]\n",
      "Scale 3: 100%|██████████| 97/97 [02:34<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of upsampled:\n",
      "Scale 0) Mean Dice: 0.6992\t Std: 0.1540\t Mean Pr. Class Dice: ['0.7885', '0.5808', '0.7285']\t Std Pr. Class: ['0.1206', '0.2356', '0.2559']\t\tMax Dice(BRATS_396.nii.gz): 0.9391\t Min Dice(BRATS_024.nii.gz): 0.2581\n",
      "Scale 1) Mean Dice: 0.6773\t Std: 0.1513\t Mean Pr. Class Dice: ['0.7708', '0.5474', '0.7137']\t Std Pr. Class: ['0.1235', '0.2428', '0.2490']\t\tMax Dice(BRATS_463.nii.gz): 0.9208\t Min Dice(BRATS_024.nii.gz): 0.2418\n",
      "Scale 2) Mean Dice: 0.6202\t Std: 0.1332\t Mean Pr. Class Dice: ['0.7321', '0.4658', '0.6628']\t Std Pr. Class: ['0.1270', '0.2440', '0.2416']\t\tMax Dice(BRATS_463.nii.gz): 0.8517\t Min Dice(BRATS_302.nii.gz): 0.1505\n",
      "Scale 3) Mean Dice: 0.4929\t Std: 0.1338\t Mean Pr. Class Dice: ['0.6186', '0.3666', '0.4936']\t Std Pr. Class: ['0.1457', '0.2641', '0.2860']\t\tMax Dice(BRATS_115.nii.gz): 0.8442\t Min Dice(BRATS_302.nii.gz): 0.1307\n",
      "Mean Dice across all scales: 0.6224 \t Std: 0.0801\n",
      "Mean Dice across all scales of classess: ['0.7275', '0.4901', '0.6497'] \t Std: ['0.0661', '0.0827', '0.0933']\n",
      "Latex: 0.6992 \\pm 0.1540 & 0.6773 \\pm 0.1513 & 0.6202 \\pm 0.1332 & 0.4929 \\pm 0.1338 & 0.6224 \\pm 0.0801 \\\\\n",
      "\n",
      "\n",
      "\n",
      "BackboneAugmented: MODE=inference\n",
      "******************* TEST Pad/upsamp BrainTumour | Best U-Net-aug3D *******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 97/97 [02:46<00:00,  1.72s/it]\n",
      "Scale 1: 100%|██████████| 97/97 [02:22<00:00,  1.47s/it]\n",
      "Scale 2: 100%|██████████| 97/97 [02:16<00:00,  1.40s/it]\n",
      "Scale 3: 100%|██████████| 97/97 [02:16<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of pad:\n",
      "Scale 0) Mean Dice: 0.6881\t Std: 0.1437\t Mean Pr. Class Dice: ['0.7730', '0.5661', '0.7250']\t Std Pr. Class: ['0.1262', '0.2220', '0.2477']\t\tMax Dice(BRATS_396.nii.gz): 0.9123\t Min Dice(BRATS_380.nii.gz): 0.2664\n",
      "Scale 1) Mean Dice: 0.0724\t Std: 0.0576\t Mean Pr. Class Dice: ['0.0707', '0.0577', '0.0888']\t Std Pr. Class: ['0.0542', '0.1074', '0.1246']\t\tMax Dice(BRATS_024.nii.gz): 0.3333\t Min Dice(BRATS_017.nii.gz): 0.0000\n",
      "Scale 2) Mean Dice: 0.0325\t Std: 0.0383\t Mean Pr. Class Dice: ['0.0063', '0.0396', '0.0518']\t Std Pr. Class: ['0.0109', '0.0817', '0.0704']\t\tMax Dice(BRATS_475.nii.gz): 0.1616\t Min Dice(BRATS_017.nii.gz): 0.0000\n",
      "Scale 3) Mean Dice: 0.0457\t Std: 0.0936\t Mean Pr. Class Dice: ['0.0022', '0.0354', '0.0995']\t Std Pr. Class: ['0.0124', '0.1743', '0.2308']\t\tMax Dice(BRATS_024.nii.gz): 0.3636\t Min Dice(BRATS_016.nii.gz): 0.0000\n",
      "Mean Dice across all scales: 0.2097 \t Std: 0.2766\n",
      "Mean Dice across all scales of classess: ['0.2130', '0.1747', '0.2413'] \t Std: ['0.3245', '0.2261', '0.2799']\n",
      "Latex: 0.6881 \\pm 0.1437 & 0.0724 \\pm 0.0576 & 0.0325 \\pm 0.0383 & 0.0457 \\pm 0.0936 & 0.2097 \\pm 0.2766 \\\\\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 97/97 [02:47<00:00,  1.72s/it]\n",
      "Scale 1: 100%|██████████| 97/97 [02:36<00:00,  1.62s/it]\n",
      "Scale 2: 100%|██████████| 97/97 [02:38<00:00,  1.63s/it]\n",
      "Scale 3: 100%|██████████| 97/97 [02:35<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of upsampled:\n",
      "Scale 0) Mean Dice: 0.6881\t Std: 0.1437\t Mean Pr. Class Dice: ['0.7730', '0.5661', '0.7250']\t Std Pr. Class: ['0.1262', '0.2220', '0.2477']\t\tMax Dice(BRATS_396.nii.gz): 0.9123\t Min Dice(BRATS_380.nii.gz): 0.2664\n",
      "Scale 1) Mean Dice: 0.6734\t Std: 0.1390\t Mean Pr. Class Dice: ['0.7643', '0.5364', '0.7196']\t Std Pr. Class: ['0.1267', '0.2357', '0.2345']\t\tMax Dice(BRATS_396.nii.gz): 0.9008\t Min Dice(BRATS_380.nii.gz): 0.2554\n",
      "Scale 2) Mean Dice: 0.6268\t Std: 0.1184\t Mean Pr. Class Dice: ['0.7364', '0.4645', '0.6795']\t Std Pr. Class: ['0.1277', '0.2355', '0.2188']\t\tMax Dice(BRATS_396.nii.gz): 0.8351\t Min Dice(BRATS_380.nii.gz): 0.2037\n",
      "Scale 3) Mean Dice: 0.5089\t Std: 0.1191\t Mean Pr. Class Dice: ['0.6372', '0.3763', '0.5131']\t Std Pr. Class: ['0.1395', '0.2576', '0.2669']\t\tMax Dice(BRATS_115.nii.gz): 0.8394\t Min Dice(BRATS_374.nii.gz): 0.2891\n",
      "Mean Dice across all scales: 0.6243 \t Std: 0.0704\n",
      "Mean Dice across all scales of classess: ['0.7277', '0.4858', '0.6593'] \t Std: ['0.0540', '0.0732', '0.0862']\n",
      "Latex: 0.6881 \\pm 0.1437 & 0.6734 \\pm 0.1390 & 0.6268 \\pm 0.1184 & 0.5089 \\pm 0.1191 & 0.6243 \\pm 0.0704 \\\\\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_backbone(model_dir_str, desc: str = \"\", depth: int = 3):\n",
    "\tif model_dir_str is None or model_dir_str == \"\":\n",
    "\t\tprint(\"No model directory provided.\")\n",
    "\t\treturn\n",
    "\tif not model_dir_str.startswith(\"/home/si-hj/Desktop/medsegnet/\"):\n",
    "\t\tmodel_dir_str = \"/home/si-hj/Desktop/medsegnet/\" + model_dir_str\n",
    "\tmodel_dir = Path(model_dir_str)\n",
    "\tmodel_path, cfg = model_params(model_dir)\n",
    "\t\n",
    "\tscales = list(range(depth+1))\n",
    "\n",
    "\n",
    "\tbase_dir = Path(cfg.dataset.base_path)\n",
    "\tif not str(base_dir).endswith(\"_test1\"):\n",
    "\t\tbase_dir = Path(f\"{base_dir}_test1\")\n",
    "\n",
    "\tpad_dir = base_dir / \"fullres\" / \"pad\"\n",
    "\tupsampling_dir = base_dir / \"fullres\" / \"upsampled\"\n",
    "\tdatasets = {}\n",
    "\n",
    "\tdef get_dataset(base_name_dir, name):\n",
    "\t\tdatasets[name] = {}\n",
    "\t\tfor scale in scales:\n",
    "\t\t\timg_dir = os.path.join(base_name_dir, f\"scale{scale}\", \"imagesTs\")\n",
    "\t\t\tlbl_dir = os.path.join(base_dir, \"lowres\", \"downsampled\", f\"scale{scale}\", \"labelsTs\")\n",
    "\t\t\timg_dir_sort = sorted(os.listdir(img_dir))\n",
    "\t\t\tlbl_dir_sort = sorted(os.listdir(lbl_dir))\n",
    "\t\t\tif (cfg.dataset.name == \"Task01_BrainTumour\"):\n",
    "\t\t\t\tdataset = ModalitiesDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\t\t\telse:\n",
    "\t\t\t\tdataset = MedicalDecathlonDataset(cfg, \"test\", img_dir_sort, lbl_dir_sort, str(img_dir), str(lbl_dir))\n",
    "\t\t\tdatasets[name][scale] = dataset\n",
    "\n",
    "\tget_dataset(pad_dir, \"pad\")\n",
    "\tget_dataset(upsampling_dir, \"upsampled\")\n",
    "\n",
    "\tmodel = instantiate(cfg.architecture.path, cfg, mode=\"inference\")\n",
    "\n",
    "\tcheckpoint = torch.load(model_path, map_location=device)\n",
    "\tmodel_state_dict = checkpoint[\"model_state_dict\"]\n",
    "\tmodel.load_state_dict(model_state_dict)\n",
    "\tmodel.to(device)\n",
    "\tmodel.eval()\n",
    "\n",
    "\t# dsc_results_per_scale = {scale: [] for scale in scales} moved this inside so its not averaged over pad and upsampled....\n",
    "\tprint(f\"******************* TEST Pad/upsamp {desc + ' ' if desc != '' else ''}*******************\")\n",
    "\tdef test(dataset, name):\n",
    "\t\tdsc_results_per_scale = {scale: [] for scale in scales} \n",
    "\t\tfor scale in scales:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tfor idx, (image, label) in tqdm(enumerate(dataset[name][scale]), desc=f\"Scale {scale}\", total=len(dataset[name][scale])):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tx = image.unsqueeze(0).float().to(device)\n",
    "\n",
    "\t\t\t\t\toutput = model.forward(x)\n",
    "\n",
    "\t\t\t\t\toutput = output.argmax(dim=1).unsqueeze(0) \n",
    "\n",
    "\t\t\t\t\ttarget_shape = tuple(label.shape)\n",
    "\n",
    "\t\t\t\t\tif name == \"pad\": # crop to target shape\n",
    "\t\t\t\t\t\tcp = tio.CropOrPad(target_shape, padding_mode=\"constant\")\n",
    "\t\t\t\t\t\ttio_image = tio.ScalarImage(tensor=output.squeeze(0))\n",
    "\n",
    "\t\t\t\t\t\tscaled_output = cp(tio_image)\n",
    "\t\t\t\t\t\tscaled_output = (scaled_output.data).unsqueeze(0)\n",
    "\t\t\t\t\telse: # downsample to target shape\n",
    "\t\t\t\t\t\tscaled_output = F.interpolate(\n",
    "\t\t\t\t\t\t\toutput.float(), size=target_shape, mode=\"nearest\"\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\tlabel = label.unsqueeze(0)\n",
    "\n",
    "\t\t\t\t\tpred = scaled_output.squeeze(0)\n",
    "\t\t\t\t\t# pred = torch.argmax(scaled_output, dim=1)\n",
    "\n",
    "\t\t\t\t\tdsc_pr_class = consistent_dice(pred.to(device), label.to(device), cfg.dataset.num_classes)\n",
    "\t\t\t\t\tdsc_results_per_scale[scale].append([dsc_class.item() for dsc_class in dsc_pr_class])\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\tprint(f\"Results per scale of {name}:\")\n",
    "\t\tprint_results(dsc_results_per_scale, dataset[name], latex=True)\n",
    "\t\treturn dsc_results_per_scale\n",
    "\t\t\n",
    "\tpad_res = test(datasets, \"pad\")\n",
    "\tup_res = test(datasets, \"upsampled\")\n",
    "\tprint(\"\\n\")\n",
    "\treturn pad_res, up_res\n",
    "\n",
    "\n",
    "# Hippocampus\n",
    "print(f\"{'*' * 20} HippoCampus {'*' * 20}\")\n",
    "hp_res[\"bb_pad\"], hp_res[\"bb_up\"] = test_backbone(_dataset_config['Task04_Hippocampus']['best_models_paths'].get('bb'), \"HippoCampus | Best U-Net3D\")\n",
    "hp_res[\"bb-aug_pad\"], hp_res[\"bb-aug_up\"] = test_backbone(_dataset_config['Task04_Hippocampus']['best_models_paths'].get('aug'), \"HippoCampus | Best U-Net-aug3D\")\n",
    "\n",
    "# Prostate\n",
    "print(f\"{'*' * 20} Prostate {'*' * 20}\")\n",
    "# test_backbone(_dataset_config['Task05_Prostate']['best_models_paths'].get('bb'), \"Prostate | Best U-Net3D\")\n",
    "# test_backbone(_dataset_config['Task05_Prostate']['best_models_paths'].get('aug'), \"Prostate | Best U-Net-aug3D\")\n",
    "\n",
    "# Braintumour\n",
    "print(f\"{'*' * 20} BrainTumour {'*' * 20}\")\n",
    "bt_res[\"bb_pad\"], bt_res[\"bb_up\"] = test_backbone(_dataset_config['Task01_BrainTumour']['best_models_paths'].get('bb'), \"BrainTumour | Best U-Net3D\")\n",
    "bt_res[\"bb-aug_pad\"], bt_res[\"bb-aug_up\"] = test_backbone(_dataset_config['Task01_BrainTumour']['best_models_paths'].get('aug'), \"BrainTumour | Best U-Net-aug3D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSimulation -- NNUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** HippocCampus ********************\n",
      "TEST LowRes HP - Pad Best achieved for nnU-net:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0:   0%|          | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:01<00:00, 38.12it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:01<00:00, 35.70it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:01<00:00, 34.39it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:01<00:00, 35.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.8797\t Std: 0.0321\t Mean Pr. Class Dice: ['0.8887', '0.8706']\t Std Pr. Class: ['0.0329', '0.0344']\n",
      "Scale 1) Mean Dice: 0.8195\t Std: 0.0448\t Mean Pr. Class Dice: ['0.8346', '0.8043']\t Std Pr. Class: ['0.0384', '0.0628']\n",
      "Scale 2) Mean Dice: 0.5285\t Std: 0.0966\t Mean Pr. Class Dice: ['0.5517', '0.5053']\t Std Pr. Class: ['0.1107', '0.1128']\n",
      "Scale 3) Mean Dice: 0.0297\t Std: 0.0619\t Mean Pr. Class Dice: ['0.0539', '0.0055']\t Std Pr. Class: ['0.1200', '0.0392']\n",
      "Mean Dice across all scales: 0.5643 \t Std: 0.3360\n",
      "Mean Dice across all scales of classess: ['0.5822', '0.5465'] \t Std: ['0.3308', '0.3413']\n",
      "Latex: 0.8797 \\pm 0.0321 & 0.8195 \\pm 0.0448 & 0.5285 \\pm 0.0966 & 0.0297 \\pm 0.0619 & 0.5643 \\pm 0.3360 \\\\\n",
      "\n",
      "TEST LowRes HP - Upsampled Best achieved for nnU-net:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 52/52 [00:00<00:00, 203.13it/s]\n",
      "Scale 1: 100%|██████████| 52/52 [00:00<00:00, 315.25it/s]\n",
      "Scale 2: 100%|██████████| 52/52 [00:00<00:00, 338.12it/s]\n",
      "Scale 3: 100%|██████████| 52/52 [00:00<00:00, 332.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.8797\t Std: 0.0321\t Mean Pr. Class Dice: ['0.8887', '0.8707']\t Std Pr. Class: ['0.0329', '0.0344']\n",
      "Scale 1) Mean Dice: 0.8197\t Std: 0.0666\t Mean Pr. Class Dice: ['0.8315', '0.8079']\t Std Pr. Class: ['0.0665', '0.0751']\n",
      "Scale 2) Mean Dice: 0.5972\t Std: 0.1062\t Mean Pr. Class Dice: ['0.5857', '0.6087']\t Std Pr. Class: ['0.1348', '0.1212']\n",
      "Scale 3) Mean Dice: 0.0551\t Std: 0.0847\t Mean Pr. Class Dice: ['0.0872', '0.0230']\t Std Pr. Class: ['0.1348', '0.0815']\n",
      "Mean Dice across all scales: 0.5879 \t Std: 0.3251\n",
      "Mean Dice across all scales of classess: ['0.5983', '0.5776'] \t Std: ['0.3163', '0.3345']\n",
      "Latex: 0.8797 \\pm 0.0321 & 0.8197 \\pm 0.0666 & 0.5972 \\pm 0.1062 & 0.0551 \\pm 0.0847 & 0.5879 \\pm 0.3251 \\\\\n",
      "\n",
      "******************** BrainTumour ********************\n",
      "TEST LowRes BT - Pad | Best achieved for nnU-net:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 97/97 [00:13<00:00,  7.34it/s]\n",
      "Scale 1: 100%|██████████| 97/97 [00:08<00:00, 10.97it/s]\n",
      "Scale 2: 100%|██████████| 97/97 [00:08<00:00, 11.58it/s]\n",
      "Scale 3: 100%|██████████| 97/97 [00:08<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.7124\t Std: 0.1518\t Mean Pr. Class Dice: ['0.7942', '0.5913', '0.7517']\t Std Pr. Class: ['0.1117', '0.2531', '0.2433']\n",
      "Scale 1) Mean Dice: 0.6696\t Std: 0.1524\t Mean Pr. Class Dice: ['0.7653', '0.5375', '0.7060']\t Std Pr. Class: ['0.1201', '0.2559', '0.2477']\n",
      "Scale 2) Mean Dice: 0.5828\t Std: 0.1278\t Mean Pr. Class Dice: ['0.6818', '0.4682', '0.5984']\t Std Pr. Class: ['0.1332', '0.2340', '0.2295']\n",
      "Scale 3) Mean Dice: 0.3990\t Std: 0.1253\t Mean Pr. Class Dice: ['0.4905', '0.3298', '0.3766']\t Std Pr. Class: ['0.1690', '0.2107', '0.2372']\n",
      "Mean Dice across all scales: 0.5909 \t Std: 0.1203\n",
      "Mean Dice across all scales of classess: ['0.6830', '0.4817', '0.6082'] \t Std: ['0.1185', '0.0980', '0.1448']\n",
      "Latex: 0.7124 \\pm 0.1518 & 0.6696 \\pm 0.1524 & 0.5828 \\pm 0.1278 & 0.3990 \\pm 0.1253 & 0.5909 \\pm 0.1203 \\\\\n",
      "\n",
      "TEST LowRes BT - Upsampled | Best achieved for nnU-net:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scale 0: 100%|██████████| 97/97 [00:12<00:00,  7.97it/s]\n",
      "Scale 1: 100%|██████████| 97/97 [00:04<00:00, 20.88it/s]\n",
      "Scale 2: 100%|██████████| 97/97 [00:03<00:00, 24.32it/s]\n",
      "Scale 3: 100%|██████████| 97/97 [00:03<00:00, 28.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results per scale of lowres:\n",
      "Scale 0) Mean Dice: 0.7124\t Std: 0.1518\t Mean Pr. Class Dice: ['0.7942', '0.5913', '0.7517']\t Std Pr. Class: ['0.1117', '0.2531', '0.2433']\n",
      "Scale 1) Mean Dice: 0.6597\t Std: 0.1551\t Mean Pr. Class Dice: ['0.7500', '0.5184', '0.7109']\t Std Pr. Class: ['0.1266', '0.2546', '0.2496']\n",
      "Scale 2) Mean Dice: 0.5954\t Std: 0.1403\t Mean Pr. Class Dice: ['0.6984', '0.4442', '0.6435']\t Std Pr. Class: ['0.1374', '0.2444', '0.2533']\n",
      "Scale 3) Mean Dice: 0.4524\t Std: 0.1447\t Mean Pr. Class Dice: ['0.5535', '0.3214', '0.4822']\t Std Pr. Class: ['0.1854', '0.2329', '0.2877']\n",
      "Mean Dice across all scales: 0.6050 \t Std: 0.0974\n",
      "Mean Dice across all scales of classess: ['0.6990', '0.4688', '0.6471'] \t Std: ['0.0906', '0.0997', '0.1027']\n",
      "Latex: 0.7124 \\pm 0.1518 & 0.6597 \\pm 0.1551 & 0.5954 \\pm 0.1403 & 0.4524 \\pm 0.1447 & 0.6050 \\pm 0.0974 \\\\\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pp\n",
    "from sympy import factor\n",
    "import yaml\n",
    "\n",
    "\n",
    "def test_nnUNet(pred_dir_str, desc: str = \"\", depth: int = 3):\n",
    "\tscales = list(range(depth+1))\n",
    "\n",
    "\tdataset_short_name, dataset_type = pred_dir_str.split(\"/\")\n",
    "\n",
    "\tdsc_results_per_scale = {scale: [] for scale in scales}\n",
    "\tprint(f\"TEST LowRes{' ' + desc if desc != '' else ''}:\")\n",
    "\tdataset = {\n",
    "\t\t\"hp\": \"Task04_Hippocampus\",\n",
    "\t\t\"bt\": \"Task01_BrainTumour\",\n",
    "\t\t\"p\": \"Task05_Prostate\",\n",
    "\t}\n",
    "\tdataset_name = dataset[dataset_short_name]\n",
    "\n",
    "\tfor scale in scales:\n",
    "\t\tlabel_name_str = f\"/home/si-hj/Desktop/datasets/{dataset_name}_test1/lowres/downsampled/scale{scale}/labelsTs\" \n",
    "\t\tlabel_name_dir = Path(label_name_str)\n",
    "\n",
    "\t\tpred_name_str = f\"/home/si-hj/Desktop/nn-unet/predictions/{pred_dir_str}/scale{scale}\"\n",
    "\t\tpred_name_dir = Path(pred_name_str)\n",
    "\t\t\n",
    "\t\timage_files = sorted([f for f in os.listdir(pred_name_dir) if f.endswith(\".nii.gz\")])\n",
    "\t\tlabel_files = sorted([f for f in os.listdir(label_name_dir) if f.endswith(\".nii.gz\")])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tfor img_file, label_file in tqdm(zip(image_files, label_files), desc=f\"Scale {scale}\", total=len(image_files)):\n",
    "\t\t\timg_path = pred_name_dir / img_file\n",
    "\t\t\tlabel_path = label_name_dir / label_file\n",
    "\t\t\t\n",
    "\n",
    "\t\t\timage = nib.load(str(img_path)).get_fdata() # (W, H, D)\n",
    "\t\t\tscaled_label = nib.load(str(label_path)).get_fdata() # (W, H, D)\n",
    "\n",
    "\t\t\tfactor = 1 / (2 ** scale)\n",
    "\t\t\tif dataset_type == \"pad\":\n",
    "\t\t\t\t# target shape\n",
    "\t\t\t\ttarget_shape = tuple(round(dim * factor) for dim in image.shape)\n",
    "\n",
    "\t\t\t\ttio_image = tio.ScalarImage(str(img_path)) # (C, W, H, D)\n",
    "\t\t\t\tcp = tio.CropOrPad(target_shape)\n",
    "\t\t\t\ttio_image = cp(tio_image)\n",
    "\t\t\t\tscaled_image = torch.from_numpy(tio_image.data.numpy()).squeeze(0) # (C, W, H, D) -> (C, D, H, W)\n",
    "\n",
    "\t\t\telif dataset_type == \"upsampled\":\n",
    "\t\t\t\ttensor = torch.from_numpy(image).unsqueeze(0).unsqueeze(0) # (W, H, D) -> (1, 1, D, H, W)\n",
    "\t\t\t\ttensor_out = F.interpolate(tensor, scale_factor=factor, mode=\"nearest\")\n",
    "\t\t\t\n",
    "\t\t\t\tscaled_image = tensor_out.squeeze(0).squeeze(0)\n",
    "\t\t\telse: \n",
    "\t\t\t\traise ValueError(f\"Unknown dataset type: {dataset_type} (available: pad, upsampled)\")\n",
    "\t\t\t\n",
    "\t\t\tscaled_label = torch.from_numpy(scaled_label)\n",
    "\n",
    "\t\t\t# get medsegnet/config/dataset/Task01_BrainTumour.yaml -> num_classes\n",
    "\t\t\tnum_classes = yaml.safe_load(open(f\"/home/si-hj/Desktop/medsegnet/config/dataset/{dataset_name}.yaml\"))['num_classes']\n",
    "\t\t\t\n",
    "\t\t\tdsc_pr_class = consistent_dice(\n",
    "\t\t\t\tscaled_image.to(device), scaled_label.to(device), num_classes\n",
    "\t\t\t)\n",
    "\t\t\tdsc_results_per_scale[scale].append([dsc_class.item() for dsc_class in dsc_pr_class])\n",
    "\t\t\t\n",
    "\tprint(f\"Results per scale of lowres:\")\n",
    "\tprint_results(dsc_results_per_scale, latex=True)\n",
    "\treturn dsc_results_per_scale\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "# Hippocampus\n",
    "print(f\"{'*' * 20} HippocCampus {'*' * 20}\")\n",
    "hp_res[\"nn_pad\"] = test_nnUNet(f\"hp/pad\", f\"HP - Pad Best achieved for nnU-net\")\n",
    "hp_res[\"nn_up\"] = test_nnUNet(f\"hp/upsampled\", f\"HP - Upsampled Best achieved for nnU-net\")\n",
    "\n",
    "# Prostate\n",
    "# print(f\"{'*' * 20} Prostate {'*' * 20}\")\n",
    "# test_nnUNet(f\"p/pad\", f\"P - Pad | Best achieved for nnU-net\")\n",
    "# test_nnUNet(f\"p/upsampled\", f\"P - Upsampled | Best achieved for nnU-net\")\n",
    "\n",
    "\n",
    "# Braintumour\n",
    "print(f\"{'*' * 20} BrainTumour {'*' * 20}\")\n",
    "bt_res[\"nn_pad\"] = test_nnUNet(f\"bt/pad\", f\"BT - Pad | Best achieved for nnU-net\")\n",
    "bt_res[\"nn_up\"] = test_nnUNet(f\"bt/upsampled\", f\"BT - Upsampled | Best achieved for nnU-net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary to print tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is for overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================== LaTeX Table Rows for Hippocampus ====================\n",
      "UNet--Pad & \\underline{0.874}$\\pm$0.037 & 0.034$\\pm$0.033 & 0.000$\\pm$0.000 & 0.000$\\pm$0.000 & 0.227$\\pm$0.374 \\\\\n",
      "UNet--Up & \\underline{0.874}$\\pm$0.037 & 0.848$\\pm$0.058 & 0.776$\\pm$0.083 & 0.334$\\pm$0.150 & 0.708$\\pm$0.219 \\\\\\midrule\n",
      "UNet+Aug--Pad & 0.871$\\pm$0.034 & 0.213$\\pm$0.034 & 0.066$\\pm$0.026 & 0.000$\\pm$0.000 & 0.287$\\pm$0.345 \\\\\n",
      "UNet+Aug--Up & 0.871$\\pm$0.034 & \\underline{0.860}$\\pm$0.039 & \\underline{0.822}$\\pm$0.069 & \\textbf{0.789}$\\pm$0.131 & \\underline{0.835}$\\pm$0.032 \\\\\\midrule\n",
      "nnUNet--Pad & \\textbf{0.880}$\\pm$0.032 & 0.819$\\pm$0.045 & 0.529$\\pm$0.097 & 0.030$\\pm$0.062 & 0.564$\\pm$0.336 \\\\\n",
      "nnUNet--Up & \\textbf{0.880}$\\pm$0.032 & 0.820$\\pm$0.067 & 0.597$\\pm$0.106 & 0.055$\\pm$0.085 & 0.588$\\pm$0.325 \\\\\\midrule\n",
      "RARE-UNet & 0.869$\\pm$0.032 & \\textbf{0.862}$\\pm$0.037 & \\textbf{0.835}$\\pm$0.063 & \\underline{0.785}$\\pm$0.134 & \\textbf{0.838}$\\pm$0.033 \\\\\n",
      "==================== End of Table ====================\n",
      "\n",
      "\n",
      "\n",
      "==================== LaTeX Table Rows for BrainTumour ====================\n",
      "UNet--Pad & \\underline{0.699}$\\pm$0.154 & 0.208$\\pm$0.124 & 0.176$\\pm$0.114 & 0.066$\\pm$0.062 & 0.287$\\pm$0.244 \\\\\n",
      "UNet--Up & \\underline{0.699}$\\pm$0.154 & \\underline{0.677}$\\pm$0.151 & 0.620$\\pm$0.133 & 0.493$\\pm$0.134 & 0.622$\\pm$0.080 \\\\\\midrule\n",
      "UNet+Aug--Pad & 0.688$\\pm$0.144 & 0.072$\\pm$0.058 & 0.033$\\pm$0.038 & 0.046$\\pm$0.094 & 0.210$\\pm$0.277 \\\\\n",
      "UNet+Aug--Up & 0.688$\\pm$0.144 & 0.673$\\pm$0.139 & \\underline{0.627}$\\pm$0.118 & \\underline{0.509}$\\pm$0.119 & \\underline{0.624}$\\pm$0.070 \\\\\\midrule\n",
      "nnUNet--Pad & \\textbf{0.712}$\\pm$0.152 & 0.670$\\pm$0.152 & 0.583$\\pm$0.128 & 0.399$\\pm$0.125 & 0.591$\\pm$0.120 \\\\\n",
      "nnUNet--Up & \\textbf{0.712}$\\pm$0.152 & 0.660$\\pm$0.155 & 0.595$\\pm$0.140 & 0.452$\\pm$0.145 & 0.605$\\pm$0.097 \\\\\\midrule\n",
      "RARE-UNet & 0.693$\\pm$0.159 & \\textbf{0.693}$\\pm$0.154 & \\textbf{0.652}$\\pm$0.138 & \\textbf{0.567}$\\pm$0.162 & \\textbf{0.651}$\\pm$0.052 \\\\\n",
      "==================== End of Table ====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_latex_table(results_dict, model_names_map, table_title, scales_order=[0, 1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Generates and prints LaTeX table rows from a dictionary of results.\n",
    "    It highlights the best (bold) and second-best (underline) values in each column\n",
    "    by comparing values rounded to 3 decimal places, correctly handling all ties.\n",
    "\n",
    "    Args:\n",
    "        results_dict (dict): The dictionary containing the model results (e.g., hp_res, bt_res).\n",
    "        model_names_map (dict): A map from keys in results_dict to display names for the table.\n",
    "        table_title (str): The title to print above the table.\n",
    "        scales_order (list): The order of scales to process.\n",
    "    \"\"\"\n",
    "    print(f\"\\n\\n{'='*20} LaTeX Table Rows for {table_title} {'='*20}\")\n",
    "    \n",
    "    # --- PASS 1: Pre-compute all data ---\n",
    "    all_models_data = []\n",
    "    model_keys_in_order = [key for key in model_names_map.keys() if key in results_dict and results_dict[key] is not None]\n",
    "\n",
    "    for model_key in model_keys_in_order:\n",
    "        dsc_results_per_scale = results_dict[model_key]\n",
    "        if not all(s in dsc_results_per_scale for s in scales_order):\n",
    "            continue\n",
    "        \n",
    "        model_means = []\n",
    "        model_stds = []\n",
    "        for scale in scales_order:\n",
    "            results_list = dsc_results_per_scale[scale]\n",
    "            results_mean_per_image = np.mean(results_list, axis=1)\n",
    "            model_means.append(np.mean(results_mean_per_image))\n",
    "            model_stds.append(np.std(results_mean_per_image))\n",
    "\n",
    "        overall_mean = np.mean(model_means)\n",
    "        overall_std = np.std(model_means)\n",
    "        model_means.append(overall_mean)\n",
    "        model_stds.append(overall_std)\n",
    "        \n",
    "        all_models_data.append({\n",
    "            'key': model_key,\n",
    "            'name': model_names_map[model_key],\n",
    "            'means': model_means,\n",
    "            'stds': model_stds\n",
    "        })\n",
    "\n",
    "    if not all_models_data:\n",
    "        print(f\"No valid data found for table: {table_title}\")\n",
    "        return\n",
    "\n",
    "    # --- PASS 2: Analyze columns using rounded values and generate table ---\n",
    "    means_array = np.array([data['means'] for data in all_models_data])\n",
    "    num_cols = means_array.shape[1]\n",
    "    \n",
    "    max_vals_per_col = []\n",
    "    second_max_vals_per_col = []\n",
    "\n",
    "    for j in range(num_cols):\n",
    "        # --- ROBUST LOGIC USING ROUNDING ---\n",
    "        # 1. Round all values in the column to 3 decimal places for comparison\n",
    "        col_values_rounded = np.round(means_array[:, j], 3)\n",
    "        \n",
    "        # 2. Get the unique sorted values from the rounded data\n",
    "        unique_sorted_desc = np.unique(col_values_rounded)[::-1]\n",
    "        \n",
    "        # 3. Assign the top two unique rounded values\n",
    "        max_val = unique_sorted_desc[0] if len(unique_sorted_desc) > 0 else -1.0\n",
    "        second_max_val = unique_sorted_desc[1] if len(unique_sorted_desc) > 1 else -1.0\n",
    "        \n",
    "        max_vals_per_col.append(max_val)\n",
    "        second_max_vals_per_col.append(second_max_val)\n",
    "\n",
    "    # --- Print Data Rows ---\n",
    "    for i, model_data in enumerate(all_models_data):\n",
    "        latex_parts = []\n",
    "        for j in range(num_cols):\n",
    "            mean = model_data['means'][j]\n",
    "            std = model_data['stds'][j]\n",
    "            \n",
    "            # Use the original mean for display formatting, but the rounded mean for logic\n",
    "            mean_for_comparison = round(mean, 3)\n",
    "            mean_str_for_display = f\"{mean:.3f}\"\n",
    "            \n",
    "            max_val = max_vals_per_col[j]\n",
    "            second_max_val = second_max_vals_per_col[j]\n",
    "\n",
    "            # Compare the rounded value against the stored rounded max/second_max\n",
    "            if mean_for_comparison == max_val:\n",
    "                formatted_mean = f\"\\\\textbf{{{mean_str_for_display}}}\"\n",
    "            elif mean_for_comparison == second_max_val:\n",
    "                formatted_mean = f\"\\\\underline{{{mean_str_for_display}}}\"\n",
    "            else:\n",
    "                formatted_mean = mean_str_for_display\n",
    "            \n",
    "            latex_parts.append(f\"{formatted_mean}$\\\\pm${std:.3f}\")\n",
    "        \n",
    "        row_content = \" & \".join(latex_parts)\n",
    "        \n",
    "        model_key = model_data['key']\n",
    "        \n",
    "        if model_key.endswith('_up') and i < len(all_models_data) - 1:\n",
    "             print(f\"{model_data['name']} & {row_content} \\\\\\\\\\\\midrule\")\n",
    "        else:\n",
    "             print(f\"{model_data['name']} & {row_content} \\\\\\\\\")\n",
    "\n",
    "    print(f\"{'='*20} End of Table {'='*20}\\n\")\n",
    "\n",
    "\n",
    "# The rest of your script remains the same\n",
    "model_names = {\n",
    "    \"bb_pad\": \"UNet--Pad\",\n",
    "    \"bb_up\": \"UNet--Up\",\n",
    "    \"bb-aug_pad\": \"UNet+Aug--Pad\",\n",
    "    \"bb-aug_up\": \"UNet+Aug--Up\",\n",
    "    \"nn_pad\": \"nnUNet--Pad\",\n",
    "    \"nn_up\": \"nnUNet--Up\",\n",
    "    \"our\": \"RARE-UNet\",\n",
    "}\n",
    "\n",
    "# The rest of your script, including where you call this function, remains the same.\n",
    "generate_latex_table(hp_res, model_names, \"Hippocampus\")\n",
    "generate_latex_table(bt_res, model_names, \"BrainTumour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is for all the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================== LaTeX Table for Per-Class DSC (Grouped) ====================\n",
      "UNet-- (1) & \\underline{0.886}$\\pm$0.031 & \\underline{0.862}$\\pm$0.050 & \\underline{0.788}$\\pm$0.121 & 0.581$\\pm$0.236 & \\underline{0.728}$\\pm$0.256 \\\\\n",
      "UNet+Aug-- (1) & 0.879$\\pm$0.033 & \\underline{0.862}$\\pm$0.038 & 0.773$\\pm$0.126 & 0.566$\\pm$0.222 & 0.725$\\pm$0.248 \\\\\n",
      "nnUNet-- (1) & \\textbf{0.889}$\\pm$0.033 & \\textbf{0.871}$\\pm$0.034 & \\textbf{0.794}$\\pm$0.112 & \\textbf{0.591}$\\pm$0.253 & \\textbf{0.752}$\\pm$0.243 \\\\\n",
      "RARE-UNet (1) & 0.878$\\pm$0.032 & 0.860$\\pm$0.037 & 0.778$\\pm$0.128 & \\underline{0.586}$\\pm$0.230 & 0.717$\\pm$0.263 \\\\\n",
      "\\midrule\n",
      "UNet-- Pad (1/2) & 0.013$\\pm$0.036 & 0.056$\\pm$0.058 & 0.332$\\pm$0.226 & 0.253$\\pm$0.246 & 0.041$\\pm$0.050 \\\\\n",
      "UNet-- Up (1/2) & 0.864$\\pm$0.046 & 0.831$\\pm$0.079 & \\underline{0.771}$\\pm$0.124 & \\underline{0.547}$\\pm$0.243 & \\underline{0.714}$\\pm$0.249 \\\\\n",
      "UNet+Aug-- Pad (1/2) & 0.258$\\pm$0.050 & 0.168$\\pm$0.040 & 0.071$\\pm$0.054 & 0.058$\\pm$0.107 & 0.089$\\pm$0.125 \\\\\n",
      "UNet+Aug-- Up (1/2) & \\underline{0.866}$\\pm$0.040 & \\underline{0.854}$\\pm$0.045 & 0.764$\\pm$0.127 & 0.536$\\pm$0.236 & \\textbf{0.720}$\\pm$0.235 \\\\\n",
      "nnUNet-- Pad (1/2) & 0.835$\\pm$0.038 & 0.804$\\pm$0.063 & 0.765$\\pm$0.120 & 0.537$\\pm$0.256 & 0.706$\\pm$0.248 \\\\\n",
      "nnUNet-- Up (1/2) & 0.831$\\pm$0.066 & 0.808$\\pm$0.075 & 0.750$\\pm$0.127 & 0.518$\\pm$0.255 & 0.711$\\pm$0.250 \\\\\n",
      "RARE-UNet (1/2) & \\textbf{0.868}$\\pm$0.041 & \\textbf{0.856}$\\pm$0.042 & \\textbf{0.788}$\\pm$0.120 & \\textbf{0.587}$\\pm$0.231 & 0.706$\\pm$0.266 \\\\\n",
      "\\midrule\n",
      "UNet-- Pad (1/4) & 0.000$\\pm$0.000 & 0.000$\\pm$0.000 & 0.276$\\pm$0.194 & 0.220$\\pm$0.239 & 0.032$\\pm$0.032 \\\\\n",
      "UNet-- Up (1/4) & 0.788$\\pm$0.071 & 0.765$\\pm$0.118 & 0.732$\\pm$0.127 & 0.466$\\pm$0.244 & 0.663$\\pm$0.242 \\\\\n",
      "UNet+Aug-- Pad (1/4) & 0.104$\\pm$0.044 & 0.028$\\pm$0.023 & 0.006$\\pm$0.011 & 0.040$\\pm$0.082 & 0.052$\\pm$0.070 \\\\\n",
      "UNet+Aug-- Up (1/4) & \\underline{0.831}$\\pm$0.087 & \\underline{0.813}$\\pm$0.073 & \\underline{0.736}$\\pm$0.128 & 0.464$\\pm$0.236 & \\textbf{0.680}$\\pm$0.219 \\\\\n",
      "nnUNet-- Pad (1/4) & 0.552$\\pm$0.111 & 0.505$\\pm$0.113 & 0.682$\\pm$0.133 & \\underline{0.468}$\\pm$0.234 & 0.598$\\pm$0.230 \\\\\n",
      "nnUNet-- Up (1/4) & 0.586$\\pm$0.135 & 0.609$\\pm$0.121 & 0.698$\\pm$0.137 & 0.444$\\pm$0.244 & 0.644$\\pm$0.253 \\\\\n",
      "RARE-UNet (1/4) & \\textbf{0.846}$\\pm$0.077 & \\textbf{0.824}$\\pm$0.064 & \\textbf{0.760}$\\pm$0.120 & \\textbf{0.524}$\\pm$0.247 & \\underline{0.671}$\\pm$0.248 \\\\\n",
      "\\midrule\n",
      "UNet-- Pad (1/8) & 0.000$\\pm$0.000 & 0.000$\\pm$0.000 & 0.098$\\pm$0.119 & 0.076$\\pm$0.138 & 0.024$\\pm$0.026 \\\\\n",
      "UNet-- Up (1/8) & 0.536$\\pm$0.233 & 0.132$\\pm$0.198 & 0.619$\\pm$0.146 & 0.367$\\pm$0.264 & 0.494$\\pm$0.286 \\\\\n",
      "UNet+Aug-- Pad (1/8) & 0.000$\\pm$0.000 & 0.000$\\pm$0.000 & 0.002$\\pm$0.012 & 0.035$\\pm$0.174 & 0.100$\\pm$0.231 \\\\\n",
      "UNet+Aug-- Up (1/8) & \\textbf{0.793}$\\pm$0.153 & \\underline{0.785}$\\pm$0.193 & \\underline{0.637}$\\pm$0.139 & \\underline{0.376}$\\pm$0.258 & \\underline{0.513}$\\pm$0.267 \\\\\n",
      "nnUNet-- Pad (1/8) & 0.054$\\pm$0.120 & 0.005$\\pm$0.039 & 0.491$\\pm$0.169 & 0.330$\\pm$0.211 & 0.377$\\pm$0.237 \\\\\n",
      "nnUNet-- Up (1/8) & 0.087$\\pm$0.135 & 0.023$\\pm$0.081 & 0.553$\\pm$0.185 & 0.321$\\pm$0.233 & 0.482$\\pm$0.288 \\\\\n",
      "RARE-UNet (1/8) & \\underline{0.779}$\\pm$0.195 & \\textbf{0.791}$\\pm$0.177 & \\textbf{0.668}$\\pm$0.146 & \\textbf{0.463}$\\pm$0.263 & \\textbf{0.570}$\\pm$0.283 \\\\\n",
      "\\midrule\n",
      "UNet-- Pad (Overall) & 0.225$\\pm$0.382 & 0.229$\\pm$0.366 & 0.374$\\pm$0.254 & 0.282$\\pm$0.185 & 0.206$\\pm$0.302 \\\\\n",
      "UNet-- Up (Overall) & 0.729$\\pm$0.140 & 0.576$\\pm$0.315 & 0.707$\\pm$0.065 & 0.460$\\pm$0.074 & 0.623$\\pm$0.094 \\\\\n",
      "UNet+Aug-- Pad (Overall) & 0.310$\\pm$0.341 & 0.265$\\pm$0.351 & 0.213$\\pm$0.324 & 0.175$\\pm$0.226 & 0.241$\\pm$0.280 \\\\\n",
      "UNet+Aug-- Up (Overall) & \\underline{0.830}$\\pm$0.030 & \\underline{0.817}$\\pm$0.028 & \\underline{0.713}$\\pm$0.055 & 0.459$\\pm$0.065 & \\underline{0.637}$\\pm$0.089 \\\\\n",
      "nnUNet-- Pad (Overall) & 0.582$\\pm$0.331 & 0.546$\\pm$0.341 & 0.683$\\pm$0.119 & \\underline{0.482}$\\pm$0.098 & 0.608$\\pm$0.145 \\\\\n",
      "nnUNet-- Up (Overall) & 0.501$\\pm$0.310 & 0.480$\\pm$0.333 & 0.667$\\pm$0.083 & 0.428$\\pm$0.081 & 0.612$\\pm$0.096 \\\\\n",
      "RARE-UNet (Overall) & \\textbf{0.843}$\\pm$0.039 & \\textbf{0.833}$\\pm$0.028 & \\textbf{0.748}$\\pm$0.047 & \\textbf{0.540}$\\pm$0.051 & \\textbf{0.666}$\\pm$0.058 \\\\\n",
      "==================== End of Table ====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_class_table_grouped(hp_res, bt_res):\n",
    "    \"\"\"\n",
    "    Generates a LaTeX table for per-class Dice scores, applying formatting\n",
    "    (bold for best, underline for second-best) INDEPENDENTLY within each scale group.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Configuration: Define the structure of the table ---\n",
    "    columns = [\n",
    "        ('HP--L', hp_res, 0), ('HP--R', hp_res, 1),\n",
    "        ('BT--PE', bt_res, 0), ('BT--NC', bt_res, 1), ('BT--ET', bt_res, 2),\n",
    "    ]\n",
    "    model_definitions = [\n",
    "        (\"UNet--\", \"bb_pad\", \"bb_up\"),\n",
    "        (\"UNet+Aug--\", \"bb-aug_pad\", \"bb-aug_up\"),\n",
    "        (\"nnUNet--\", \"nn_pad\", \"nn_up\"),\n",
    "    ]\n",
    "    rare_unet_def = (\"RARE-UNet\", \"our\")\n",
    "    scales_config = [\n",
    "        (0, \"1\"), (1, \"1/2\"), (2, \"1/4\"), (3, \"1/8\"), ('overall', \"Overall\")\n",
    "    ]\n",
    "\n",
    "    # --- PASS 1: Collect all data, tagging each row with its scale group ---\n",
    "    all_rows_data = []\n",
    "    for scale, scale_name in scales_config:\n",
    "        # Define the set of rows for the current scale group\n",
    "        group_rows = []\n",
    "        if scale == 0:\n",
    "            for model_name, pad_key, _ in model_definitions:\n",
    "                group_rows.append({'label': f\"{model_name} ({scale_name})\", 'model_key': pad_key})\n",
    "        elif scale != 'overall':\n",
    "            for model_name, pad_key, up_key in model_definitions:\n",
    "                group_rows.append({'label': f\"{model_name} Pad ({scale_name})\", 'model_key': pad_key})\n",
    "                group_rows.append({'label': f\"{model_name} Up ({scale_name})\", 'model_key': up_key})\n",
    "        \n",
    "        # Add RARE-UNet to all non-overall groups\n",
    "        if scale != 'overall':\n",
    "            group_rows.append({'label': f\"{rare_unet_def[0]} ({scale_name})\", 'model_key': rare_unet_def[1]})\n",
    "        \n",
    "        # Define rows for the 'Overall' group separately\n",
    "        if scale == 'overall':\n",
    "             for model_name, pad_key, up_key in model_definitions:\n",
    "                group_rows.append({'label': f\"{model_name} Pad ({scale_name})\", 'model_key': pad_key})\n",
    "                group_rows.append({'label': f\"{model_name} Up ({scale_name})\", 'model_key': up_key})\n",
    "             group_rows.append({'label': f\"{rare_unet_def[0]} ({scale_name})\", 'model_key': rare_unet_def[1]})\n",
    "        \n",
    "        # Calculate and store the data for each defined row\n",
    "        for row_info in group_rows:\n",
    "            row_data = {'label': row_info['label'], 'scale_group': scale_name, 'means': [], 'stds': []}\n",
    "            model_key = row_info['model_key']\n",
    "            \n",
    "            for _, res_dict, class_idx in columns:\n",
    "                if scale != 'overall':\n",
    "                    class_scores = np.array(res_dict[model_key][scale])[:, class_idx]\n",
    "                    mean, std = np.mean(class_scores), np.std(class_scores)\n",
    "                else: # Handle 'Overall' calculation for this specific row\n",
    "                    means_per_scale = []\n",
    "                    # Overall for Pad models averages scales 0,1,2,3 from the pad_key\n",
    "                    if 'Pad' in row_info['label'] or 'UNet (1' in row_info['label']:\n",
    "                        key_to_use = model_definitions[[m[0] for m in model_definitions].index(row_info['label'].split(' ')[0])][1]\n",
    "                        for s in range(4):\n",
    "                            means_per_scale.append(np.mean(np.array(res_dict[key_to_use][s])[:, class_idx]))\n",
    "                    # Overall for Up models averages scales 1,2,3 from the up_key (as there's no scale 0 for 'Up')\n",
    "                    elif 'Up' in row_info['label']:\n",
    "                         key_to_use = model_definitions[[m[0] for m in model_definitions].index(row_info['label'].split(' ')[0])][2]\n",
    "                         for s in range(1, 4):\n",
    "                            means_per_scale.append(np.mean(np.array(res_dict[key_to_use][s])[:, class_idx]))\n",
    "                    # Overall for RARE-UNet\n",
    "                    else:\n",
    "                        for s in range(4):\n",
    "                           means_per_scale.append(np.mean(np.array(res_dict[model_key][s])[:, class_idx]))\n",
    "\n",
    "                    mean, std = np.mean(means_per_scale), np.std(means_per_scale)\n",
    "                \n",
    "                row_data['means'].append(mean)\n",
    "                row_data['stds'].append(std)\n",
    "            all_rows_data.append(row_data)\n",
    "\n",
    "    # --- PASS 2: Analyze and print, group by group ---\n",
    "    print(\"\\n\\n\" + \"=\"*20 + \" LaTeX Table for Per-Class DSC (Grouped) \" + \"=\"*20)\n",
    "    \n",
    "    for idx, (scale, scale_name) in enumerate(scales_config):\n",
    "        # 1. Filter data for the current group\n",
    "        group_rows = [row for row in all_rows_data if row['scale_group'] == scale_name]\n",
    "        if not group_rows: continue\n",
    "\n",
    "        # 2. Analyze this group's columns to find best/second-best values\n",
    "        group_means_array = np.array([data['means'] for data in group_rows])\n",
    "        max_vals_for_group = []\n",
    "        second_max_vals_for_group = []\n",
    "        \n",
    "        for j in range(group_means_array.shape[1]):\n",
    "            col_values_rounded = np.round(group_means_array[:, j], 3)\n",
    "            unique_sorted_desc = np.unique(col_values_rounded)[::-1]\n",
    "            max_vals_for_group.append(unique_sorted_desc[0] if len(unique_sorted_desc) > 0 else -1.0)\n",
    "            second_max_vals_for_group.append(unique_sorted_desc[1] if len(unique_sorted_desc) > 1 else -1.0)\n",
    "\n",
    "        # 3. Print the rows for this group with the correct formatting\n",
    "        for row_data in group_rows:\n",
    "            latex_parts = []\n",
    "            for j in range(len(columns)):\n",
    "                mean, std = row_data['means'][j], row_data['stds'][j]\n",
    "                mean_for_comparison = round(mean, 3)\n",
    "                mean_str_for_display = f\"{mean:.3f}\"\n",
    "                \n",
    "                if mean_for_comparison == max_vals_for_group[j]:\n",
    "                    formatted_mean = f\"\\\\textbf{{{mean_str_for_display}}}\"\n",
    "                elif mean_for_comparison == second_max_vals_for_group[j]:\n",
    "                    formatted_mean = f\"\\\\underline{{{mean_str_for_display}}}\"\n",
    "                else:\n",
    "                    formatted_mean = mean_str_for_display\n",
    "                \n",
    "                latex_parts.append(f\"{formatted_mean}$\\\\pm${std:.3f}\")\n",
    "            \n",
    "            print(f\"{row_data['label']} & \" + \" & \".join(latex_parts) + \" \\\\\\\\\")\n",
    "\n",
    "        # 4. Print \\midrule between groups, but not after the last one\n",
    "        if idx < len(scales_config) - 1:\n",
    "            print(\"\\\\midrule\")\n",
    "            \n",
    "    print(\"=\"*20 + \" End of Table \" + \"=\"*20 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- How to use ---\n",
    "# At the end of your script, after `hp_res` and `bt_res` are populated, call:\n",
    "generate_class_table_grouped(hp_res, bt_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction when time allows or bored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path('/home/si-hj/Desktop/medsegnet')\n",
    "DATA_ROOT = Path('/home/si-hj/Desktop/datasets')\n",
    "NNUNET_PRED_ROOT = Path('/home/si-hj/Desktop/nn-unet/predictions')\n",
    "TRAINED_MODELS_ROOT = PROJECT_ROOT / \"trained_models\"\n",
    "\n",
    "# Update sys.path\n",
    "sys.path.append(str(PROJECT_ROOT.parent)) # Desktop`\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "\n",
    "DATASET_CONFIGS = {\n",
    "    \"Task01_BrainTumour\": {\n",
    "        \"num_classes\": OmegaConf.load(PROJECT_ROOT / \"config/dataset/Task01_BrainTumour.yaml\").num_classes,\n",
    "        \"dataset_class\": ModalitiesDataset,\n",
    "        \"base_path_segment\": \"Task01_BrainTumour_test1\"\n",
    "    },\n",
    "    \"Task04_Hippocampus\": {\n",
    "        \"num_classes\": OmegaConf.load(PROJECT_ROOT / \"config/dataset/Task04_Hippocampus.yaml\").num_classes,\n",
    "        \"dataset_class\": MedicalDecathlonDataset,\n",
    "        \"base_path_segment\": \"Task04_Hippocampus_test1\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# For nnU-Net (mapping short names to full names)\n",
    "NNUNET_DATASET_MAP = {\n",
    "    \"hp\": \"Task04_Hippocampus\",\n",
    "    \"bt\": \"Task01_BrainTumour\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def load_model_config(model_dir: Path) -> Tuple[Path, DictConfig, str]:\n",
    "    if not model_dir.is_dir():\n",
    "        raise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n",
    "    \n",
    "    model_path = model_dir / \"best_model.pth\"\n",
    "    cfg_path = model_dir / \"config.yaml\"\n",
    "    if not model_path.exists() or not cfg_path.exists():\n",
    "        raise FileNotFoundError(f\"best_model.pth or config.yaml not found in {model_dir}\")\n",
    "        \n",
    "    cfg = OmegaConf.load(cfg_path)\n",
    "    setup_seed(cfg.seed)\n",
    "    \n",
    "    if not isinstance(cfg, DictConfig):\n",
    "        raise TypeError(\"cfg must be a DictConfig.\")\n",
    "    \n",
    "    return model_path, cfg, cfg.dataset.name\n",
    "\n",
    "\n",
    "def get_dataset_for_scale(\n",
    "    cfg: DictConfig,\n",
    "    dataset_name_key: str, # e.g., \"Task04_Hippocampus\"\n",
    "    scale: int,\n",
    "    img_base_dir: Path,\n",
    "    lbl_base_dir: Path, # This might vary for nnU-Net where labels are always from original lowres\n",
    "    split: str = \"test\"\n",
    ") -> torch.utils.data.Dataset:\n",
    "\n",
    "    dataset_cfg = DATASET_CONFIGS[dataset_name_key]\n",
    "    DatasetClass = dataset_cfg[\"dataset_class\"]\n",
    "\n",
    "    img_dir = img_base_dir / f\"scale{scale}\" / \"imagesTs\"\n",
    "    lbl_dir = lbl_base_dir / f\"scale{scale}\" / \"labelsTs\" # Adjust if labels are always fullres/lowres\n",
    "\n",
    "    if not img_dir.exists() or not lbl_dir.exists():\n",
    "        raise FileNotFoundError(f\"Image or label directory not found for scale {scale} under {img_base_dir} or {lbl_base_dir}\")\n",
    "\n",
    "    img_files_sorted = sorted(os.listdir(img_dir))\n",
    "    lbl_files_sorted = sorted(os.listdir(lbl_dir))\n",
    "    \n",
    "    return DatasetClass(cfg, split, img_files_sorted, lbl_files_sorted, str(img_dir), str(lbl_dir))\n",
    "\n",
    "# Example usage in test_lowres\n",
    "# base_dataset_path = DATA_ROOT / DATASET_CONFIGS[dataset_name_from_cfg][\"base_path_segment\"]\n",
    "# lowres_data_root = base_dataset_path / \"lowres\" / \"downsampled\"\n",
    "# datasets[scale] = get_dataset_for_scale(cfg, dataset_name_from_cfg, scale, lowres_data_root, lowres_data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_scales(\n",
    "    model: torch.nn.Module,\n",
    "    cfg: DictConfig,\n",
    "    datasets_per_scale: Dict[int, torch.utils.data.Dataset],\n",
    "    device: torch.device,\n",
    "    prediction_processor_fn: callable, # Takes model output, label shape, returns processed pred\n",
    "    desc_prefix: str = \"\"\n",
    ") -> Dict[int, list]:\n",
    "    \n",
    "    dsc_results = {scale: [] for scale in datasets_per_scale.keys()}\n",
    "    model.eval()\n",
    "\n",
    "    for scale, dataset in datasets_per_scale.items():\n",
    "        dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=cfg.training.num_workers)\n",
    "        with torch.no_grad():\n",
    "            for idx, (image, label) in tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"{desc_prefix} Scale {scale}\"):\n",
    "                \n",
    "                # Common part: move image to device\n",
    "                image_dev = image.to(device) # Assuming image always needs .to(device)\n",
    "                                            # For backbone, it's image.unsqueeze(0).float().to(device)\n",
    "                                            # This needs standardization or to be part of prediction_processor_fn\n",
    "\n",
    "                # Model-specific inference and prediction processing\n",
    "                # This part would be handled by prediction_processor_fn\n",
    "                # Example: output = model(image_dev) or model.run_inference(image_dev)\n",
    "                #          scaled_output = post_process(output, label.shape)\n",
    "                #          pred = torch.argmax(scaled_output, dim=1).squeeze(0)\n",
    "                \n",
    "                pred = prediction_processor_fn(model, image_dev, label.shape) # Pass label.shape for target\n",
    "                \n",
    "                label_dev = label.squeeze(0).to(device) # Assuming label always needs squeeze and .to(device)\n",
    "                \n",
    "                dsc_pr_class = consistent_dice(pred, label_dev, cfg) # cfg needs num_classes\n",
    "                dsc_results[scale].append([dsc_class.item() for dsc_class in dsc_pr_class])\n",
    "                \n",
    "                # Optional: conditional plotting logic here or passed as another callback\n",
    "    return dsc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lowres(model_dir_str: str, desc: str = \"\", num_ms_levels: int = 3):\n",
    "    model_dir = Path(model_dir_str)\n",
    "    model_path, cfg, dataset_name_from_cfg = load_model_config(model_dir) # Updated\n",
    "\n",
    "    scales = list(range(num_ms_levels + 1))\n",
    "\n",
    "    dataset_cfg_details = DATASET_CONFIGS[dataset_name_from_cfg]\n",
    "    base_data_path = DATA_ROOT / dataset_cfg_details[\"base_path_segment\"]\n",
    "    lowres_data_root = base_data_path / \"lowres\" / \"downsampled\"\n",
    "\n",
    "    datasets = {}\n",
    "    filenames_per_scale = {} # For print_results if needed\n",
    "\n",
    "    for scale in scales:\n",
    "        # Use the new get_dataset_for_scale\n",
    "        dataset_instance = get_dataset_for_scale(cfg, dataset_name_from_cfg, scale, lowres_data_root, lowres_data_root)\n",
    "        datasets[scale] = dataset_instance\n",
    "        # If print_results needs filenames:\n",
    "        # filenames_per_scale[scale] = [dataset_instance.img_paths[i] for i in range(len(dataset_instance))]\n",
    "\n",
    "\n",
    "    model = instantiate(cfg.architecture.path, cfg, \"inference\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dsc_results_per_scale = {scale: [] for scale in scales}\n",
    "\n",
    "    print(f\"******************* TEST LowRes {desc + ' ' if desc else ''}*******************\")\n",
    "    for scale in scales:\n",
    "        dataloader = DataLoader(datasets[scale], batch_size=1, shuffle=False, num_workers=cfg.training.num_workers)\n",
    "        with torch.no_grad():\n",
    "            for idx, (image, label) in tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Scale {scale}\"):\n",
    "                output = model.run_inference(image.to(device)) # Specific to MS model\n",
    "                pred = torch.argmax(output, dim=1).squeeze(0)\n",
    "                label_squeezed = label.squeeze(0) # Keep original label for plotting if needed\n",
    "                \n",
    "                dsc_pr_class = consistent_dice(pred, label_squeezed.to(device), cfg)\n",
    "                dsc_results_per_scale[scale].append([dsc_class.item() for dsc_class in dsc_pr_class])\n",
    "\n",
    "                # Conditional plotting (can be refactored too)\n",
    "                # if plot and (scale == 0 and np.mean([d.item() for d in dsc_pr_class]) <= 0.3):\n",
    "                #    plot_img(image, pred, label_squeezed)\n",
    "\n",
    "    print(f\"Results per scale of lowres:\")\n",
    "    print_results(dsc_results_per_scale, None) # Pass filenames if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Multi-Scale\": {\n",
    "        \"LowRes\": {\n",
    "            0: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            1: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            2: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            3: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "        }\n",
    "    },\n",
    "    \"U-Net\": {\n",
    "        \"Pad\": {\n",
    "            0: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            1: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            2: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            3: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "        },\n",
    "        \"Upsample\": {\n",
    "            0: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            1: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            2: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            3: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "        }\n",
    "    },\n",
    "    \"U-Net+Aug\": {\n",
    "        \"Pad\": {\n",
    "            0: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            1: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            2: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            3: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "        },\n",
    "        \"Upsample\": {\n",
    "            0: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            1: {\"dice\": [1.0, 0.0], \"std\": [1.0, 0.0]},\n",
    "            2: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            3: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "        }\n",
    "    },\n",
    "    \"nnU-Net\": {\n",
    "        \"Pad\": {\n",
    "            0: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            1: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            2: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            3: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "        },\n",
    "        \"Upsample\": {\n",
    "            0: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            1: {\"dice\": [1.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            2: {\"dice\": [1.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "            3: {\"dice\": [0.0, 0.0], \"std\": [0.0, 0.0]},\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "  \\centering\n",
      "  \\footnotesize\n",
      "  \\caption{Mean Dice Similarity Coefficient (DSC) across scales and model families from the \\texttt{BrainTumour test} datasets.}\n",
      "  \\label{tab:mean-dsc-bt}\n",
      "\\begin{adjustbox}{max width=1.1\\textwidth}\n",
      "    \\hspace{-5em}\n",
      "    \\begin{tabular}{@{}L{2cm} C{3cm} L{2cm} C{2.5cm} C{3cm} C{3cm} c@{}}\n",
      "      \\toprule\n",
      "      \\textbf{Method} & \\textbf{DSC@res} & \\textbf{Variant} & \\textbf{DSC@res/2} & \\textbf{DSC@res/4} & \\textbf{DSC@res/8} & \\textbf{Avg. across scales} \\\\\n",
      "      \\midrule\n",
      "      \\rowcolor{gray!15}\n",
      "      Multi-Scale & $\\mathbf{0.0000} \\pm 0.0000$ & LowRes & 0.0000 $\\pm$ 0.0000 & \\underline{0.0000} $\\pm$ 0.0000 & $\\mathbf{0.0000} \\pm 0.0000$ & 0.0000 $\\pm$ 0.0000 \\\\\n",
      "      \\midrule\n",
      "      \\multirow{2}{*}{U-Net} & \\multirow{2}{*}{\\underline{0.0000} $\\pm$ 0.0000} & Pad & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 & \\underline{0.0000} $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 \\\\\n",
      "        &\n",
      "        & Upsample & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 \\\\\n",
      "      \\midrule\n",
      "      \\multirow{2}{*}{U-Net+Aug} & \\multirow{2}{*}{0.0000 $\\pm$ 0.0000} & Pad & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 \\\\\n",
      "        &\n",
      "        & Upsample & $\\mathbf{1.0000} \\pm 1.0000$ & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 & \\underline{0.2500} $\\pm$ 0.2500 \\\\\n",
      "      \\midrule\n",
      "      \\multirow{2}{*}{nnU-Net} & \\multirow{2}{*}{0.0000 $\\pm$ 0.0000} & Pad & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 & 0.0000 $\\pm$ 0.0000 \\\\\n",
      "        &\n",
      "        & Upsample & \\underline{1.0000} $\\pm$ 0.0000 & $\\mathbf{1.0000} \\pm 0.0000$ & 0.0000 $\\pm$ 0.0000 & $\\mathbf{0.5000} \\pm 0.0000$ \\\\\n",
      "      \\bottomrule\n",
      "    \\end{tabular}\n",
      "  \\end{adjustbox}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Generate the exact LaTeX table structure from `results` with zeros, matching the user’s template.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_cell(mean, std, bold=False, underline=False):\n",
    "    \"\"\"Return cell text matching the user's math formatting.\"\"\"\n",
    "    if bold:\n",
    "        return f\"$\\\\mathbf{{{mean:.4f}}} \\\\pm {std:.4f}$\"\n",
    "    if underline:\n",
    "        return f\"\\\\underline{{{mean:.4f}}} $\\\\pm$ {std:.4f}\"\n",
    "    return f\"{mean:.4f} $\\\\pm$ {std:.4f}\"\n",
    "\n",
    "# Flatten rows and compute per-scale mean/std using only the first class,\n",
    "# average only for the final column\n",
    "rows = []\n",
    "for method, variants in results.items():\n",
    "    for variant, scales in variants.items():\n",
    "        # Use only the first class's metrics for wide table columns\n",
    "        means = [scales[s][\"dice\"][0] for s in range(4)]\n",
    "        stds  = [scales[s][\"std\"][0] for s in range(4)]\n",
    "        avg_mean, avg_std = np.mean(means), np.mean(stds)\n",
    "        rows.append({\n",
    "            \"method\": method,\n",
    "            \"variant\": variant,\n",
    "            0:  (means[0], stds[0]),\n",
    "            1:  (means[1], stds[1]),\n",
    "            2:  (means[2], stds[2]),\n",
    "            3:  (means[3], stds[3]),\n",
    "            \"avg\": (avg_mean, avg_std)\n",
    "        })\n",
    "\n",
    "# Find top-2 for each column by mean\n",
    "cols = [0, 1, 2, 3, \"avg\"]\n",
    "top2 = {c: sorted(rows, key=lambda r: r[c][0], reverse=True)[:2] for c in cols}\n",
    "\n",
    "# Build and print LaTeX\n",
    "lines = []\n",
    "a = lines.append\n",
    "a(r\"\\begin{table}[H]\")\n",
    "a(r\"  \\centering\")\n",
    "a(r\"  \\footnotesize\")\n",
    "a(r\"  \\caption{Mean Dice Similarity Coefficient (DSC) across scales and model families from the \\texttt{BrainTumour test} datasets.}\")\n",
    "a(r\"  \\label{tab:mean-dsc-bt}\")\n",
    "a(r\"\\begin{adjustbox}{max width=1.1\\textwidth}\")\n",
    "a(r\"    \\hspace{-5em}\")\n",
    "a(r\"    \\begin{tabular}{@{}L{2cm} C{3cm} L{2cm} C{2.5cm} C{3cm} C{3cm} c@{}}\")\n",
    "a(r\"      \\toprule\")\n",
    "a(r\"      \\textbf{Method} & \\textbf{DSC@res} & \\textbf{Variant} & \\textbf{DSC@res/2} & \\textbf{DSC@res/4} & \\textbf{DSC@res/8} & \\textbf{Avg. across scales} \\\\\")\n",
    "a(r\"      \\midrule\")\n",
    "\n",
    "for method, variants in results.items():\n",
    "    if len(variants) == 1:  # Multi-Scale\n",
    "        var = next(iter(variants))\n",
    "        ent = next(r for r in rows if r[\"method\"]==method and r[\"variant\"]==var)\n",
    "        a(r\"      \\rowcolor{gray!15}\")\n",
    "        cells = []\n",
    "        for c in cols:\n",
    "            mean, std = ent[c]\n",
    "            bold = ent in top2[c][:1]\n",
    "            underline = ent in top2[c][1:2]\n",
    "            cells.append(format_cell(mean, std, bold, underline))\n",
    "        a(f\"      {method} & {cells[0]} & {var} & {cells[1]} & {cells[2]} & {cells[3]} & {cells[4]} \\\\\\\\\")\n",
    "        a(r\"      \\midrule\")\n",
    "    else:\n",
    "        n = len(variants)\n",
    "        for i, var in enumerate(variants):\n",
    "            ent = next(r for r in rows if r[\"method\"]==method and r[\"variant\"]==var)\n",
    "            cells = []\n",
    "            for c in cols:\n",
    "                mean, std = ent[c]\n",
    "                bold = ent in top2[c][:1]\n",
    "                underline = ent in top2[c][1:2]\n",
    "                cells.append(format_cell(mean, std, bold, underline))\n",
    "            if i == 0:\n",
    "                a(f\"      \\\\multirow{{{n}}}{{*}}{{{method}}} & \\\\multirow{{{n}}}{{*}}{{{cells[0]}}} & {var} & {cells[1]} & {cells[2]} & {cells[3]} & {cells[4]} \\\\\\\\\")\n",
    "            else:\n",
    "                a(r\"        &\")\n",
    "                a(f\"        & {var} & {cells[1]} & {cells[2]} & {cells[3]} & {cells[4]} \\\\\\\\\")\n",
    "        a(r\"      \\midrule\")\n",
    "\n",
    "# Replace last midrule with bottomrule\n",
    "for i in range(len(lines)-1, -1, -1):\n",
    "    if lines[i].strip() == r\"\\midrule\":\n",
    "        lines[i] = r\"      \\bottomrule\"\n",
    "        break\n",
    "\n",
    "a(r\"    \\end{tabular}\")\n",
    "a(r\"  \\end{adjustbox}\")\n",
    "a(r\"\\end{table}\")\n",
    "\n",
    "print(\"\\n\".join(lines))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
